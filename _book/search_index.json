[
["index.html", "Uma introdução gentil à Ciência de Dados Prefácio", " Uma introdução gentil à Ciência de Dados Janaina Souza de Souza Júlia Carolina Bijos Kaike Wesley Reis 2021-03-01 Prefácio "],
["cap1.html", "Capítulo 1 Introdução à Ciência de Dados 1.1 O que são “dados” e onde estão presentes? 1.2 O ciclo dos Dados - Construindo uma pergunta estatística 1.3 Estruturando os dados 1.4 Identificando o tipo de problema 1.5 Considerações finais Referências", " Capítulo 1 Introdução à Ciência de Dados Provavelmente você deve estar pensando que não faz ideia do que seja Ciência de Dados, já que nunca teve contato com esta área da ciência. Mas, será mesmo? Ao longo deste capítulo vamos entender o que é a Ciência de Dados e refletir como ela está inserida no nosso dia a dia. A Ciência de Dados pode ser definida como o campo do conhecimento que busca transformar dados em informações. Mas, o que isto significa? Observe a Figura 1.1 que trata algumas situações vivenciadas na nossa cidade ou comunidade, que precisam ser adaptadas para melhorar o bem estar dos cidadãos. Você consegue imaginar como a Ciência de Dados poderia ajudar a lidar com estas dificuldades? Verifique os setores observados, os questionamentos e possíveis soluções indicados nas caixas em azul. Figura 1.1: Ciência de Dados para o bem social Esta imagem é um bom referencial de algumas aplicações da Ciência de Dados para o bem da sociedade. Além disso, mostra como podemos partir de problemas e perguntas iniciais para realizar investigações. Observe o questionamento 1, em que os ônibus não passam no horário esperado. Uma das formas de solucionar este problema é através de uma estimativa da frequência ideal de ônibus neste ponto, com base em um tempo de espera que se imagina ser adequado. Então, para definir esta frequência é necessário saber: a frequência dos ônibus que ali passam para conhecer a situação atual a quantidade de passageiros que utiliza o transporte a melhor rota que deve ser percorrida, de forma que evite atrasos no translado A definição destes tópicos é importante, pois eles indicam quais dados são necessários obter. A partir do momento que são obtidos, o processo investigativo evolui até que se saiba qual é a frequência ideal de ônibus neste ponto da cidade! Observe como temos questionamentos em tantas áreas diferentes. Isto indica que a Ciência de Dados é um campo do conhecimento que nos permite abordar problemas de uma forma abrangente e com aplicações em diversos setores! No processo da Ciência de Dados, o dado é transformado em informação relevante por meio de etapas que permitem analisar tendências e prever comportamentos futuros! Estas informações geradas permitem extrair conclusões e criar sacadas (os famosos insights ou “lampejos de ideias”) para responder a perguntas e solucionar problemas. Que tal conhecer alguns setores que tem aplicado Ciência de Dados aqui no Brasil? Transportes e Mobilidade Urbana: link 1 link 2 Saúde: link Segurança pública: link Comunicação com clientes: link Turismo: link Atividade Jurídica: link Para aplicar esta ciência é preciso ter conhecimentos de Estatística, Computação e conhecimento sobre o problema investigado! Isto porque as ferramentas de solução são baseadas nestes conteúdos, por isso eles são a essência da Ciência de Dados! Mas não se engane, estas ferramentas “matemáticas” são vinculadas à ciências sociais, biológicas, ambientais, ao setor de negócios, tecnologia, entre outros, a fim de descobrir padrões em problemas de diferentes naturezas (como vimos na Figura 1.1). Por este motivo, a Ciência de Dados é uma área interdisciplinar. A Figura 1.2 esquematiza os conteúdos básicos da Ciência de Dados. Figura 1.2: Interdisciplinaridade da Ciência de Dados Mas por quê a Ciência de Dados se tornou indispensável? A popularidade da área veio a partir do aumento de dados disponíveis atualmente. É impossível gerir tantos dados sem a utilização de computadores, que apresentam alta capacidade de processamento. Mas atenção, embora a Ciência de Dados seja favorecida pela tecnologia, é importante ressaltar que são seres humanos que direcionam, criam regras, avaliam e manuseiam todo o processo investigativo. Portanto, a criticidade de um profissional que avalie a execução de cada etapa realizada é essencial para garantir análises e interpretações coerentes a cada situação. Para compreender melhor como o processo de Ciência de Dados ocorre, vamos pensar na seguinte situação: Sabemos que atualmente o lazer está muito vinculado ao uso de tecnologias e, portanto, estamos a um clique de uma música que gostamos de ouvir, ou de um vídeo que queremos assistir, uma busca no google sobre algum tema de interesse. O fato de realizarmos estas buscas revela nossos interesses, você concorda? A partir da análise do nosso histórico de buscas, várias propagandas ou recomendações podem começar a nos ser feitas. Pense em quantas vezes você pesquisou sobre algum item e depois surgiram várias propagandas sobre ele. Ou quando você assistiu no youtube o clipe de uma banda e depois apareceram sugestões de outros clipes desta mesma banda, como na Figura 1.3. Observe que nesta imagem estamos assistindo a um vídeo da banda Coldplay, e ao lado existem várias sugestões de outras músicas deles, inclusive há uma indicação de outra banda. Figura 1.3: Mecanismo de recomendação do Youtube Que tal entender melhor como este mecanismo ocorre? Imagine que você será responsável por escolher um filme para assistir junto com seus amigos. Porém, eles disseram gostar de filmes de terror, romance, suspense, ação, comédia, ficção científica e drama. Para você ficou quase impossível escolher frente à tantas opções, já que quer ter certeza que eles irão curtir o filme. Assim, como podemos saber qual gênero de filmes deve ser escolhido? Sabendo isso, a sua escolha será certeira e a diversão estará garantida! Podemos solucionar este problema utilizando a Ciência de Dados para analisar as preferências de filme dos seus amigos, de forma similar ao mecanismo de recomendações do youtube, por exemplo. Nas próximas seções deste capítulo, vamos solucionar cada etapa desta investigação! Quer saber mais sobre onde a Ciência de Dados se aplica? Assista ao vídeo abaixo: Depois de tantos exemplos uma conclusão é real: a Ciência de Dados está por toda parte e nós, fazemos parte dela ao consumir ou gerar dados. Você concorda? 1.1 O que são “dados” e onde estão presentes? No item anterior vimos que a Ciência de Dados é algo indispensável, já que é impossível lidar com tantos dados sem o uso de tecnologias. Vimos também, que parte destes dados, somos nós quem geramos. Precisamos entender o que significa a palavra dados neste contexto. Vamos dar sequência no nosso exemplo, onde queremos descobrir qual é o gênero de filmes que você deve escolher. Para isto, podemos avaliar qual é o gênero favorito de cada amigo seu a partir dos filmes que eles assistiram recentemente e o gênero destes filmes. Desta forma, iremos verificar se eles têm a preferência em comum por algum gênero. Para iniciar a investigação, devemos criar um registro para cada pessoa, contendo características importantes coletadas para a avaliação das preferências deles, como: Nome Filmes assistidos Gênero do filme Portanto, o nosso registro irá conter observações de cada característica citada, para cada pessoa. Assim, dizemos que as observações destas determinadas características são os nossos dados. Em outras palavras: dados são observações que foram coletadas e armazenadas de alguma forma. Inicialmente, compõem apenas registros e não apresentam relevância. Qualquer dado pode ser armazenado, caso contrário não pode ser considerado um dado. O dado por si só não apresenta significado e por isso não serve para gerar respostas, interpretações e informações. Assim, somente após processar e transformá-los é que se torna possível tirar conclusões. Parte do trabalho do investigador é avaliar quais dados são de fato importantes para o processo de análise. Muitas vezes temos uma grande quantidade de dados, mas ao avaliar a natureza do problema percebemos que nem todos são fatores importantes para a situação investigada. No nosso exemplo, queremos saber qual gênero de filmes você deve escolher para assistir com seus amigos. Já vimos que algumas características são importantes para guiar a sua decisão final, mas podem existir outras que também complementariam nossos dados. Todavia, deve ser feita uma valiação sobre a importância delas para o problema abordado. Por exemplo, poderíamos coletar a altura e peso de cada amigo, mas, isso seria relevante para a nossa investigação? Claramente não, portanto não faria sentido registrar estes dados. Observe também que você obteve os dados por meio de uma pesquisa realizada com os seus amigos. Todavia, há muitas outras fontes de obtenção de dados. Basta lembrar que nós mesmos somos geramos dados quando interagimos em uma rede social. Portanto, os dados podem ser obtidos pelo uso de celulares, computadores, sensores, registros escolares, pesquisas de opinião ou qualquer forma de registro. E porquê é tão importante entendermos a definição de dados e como eles são obtidos? Basicamente, porque eles são a essência da Ciência de Dados. Sem eles não é possível gerar informações e aplicar o processo investigativo. A análise dos dados permite observar uma tendência ou padrão em processos, fenômenos na natureza ou mesmo nos nossos comportamentos. E este é o grande objetivo da Ciência de Dados, reconhecer padrões e interpretá-los para tomar boas decisões! 1.1.1 Posso compartilhar dados? Vamos voltar à nossa investigação sobre os filmes. Lembre-se que para nós é importante registrar os últimos filmes assistidos pelos nossos amigos, o gênero dos filmes e a identificação da pessoa. Podemos nos questionar se estes registros serão restritos à você que está analisando ou se serão abertos à qualquer pessoa (inclusive seus amigos). É um questionamento pertinente? Haveria algum incômodo se qualquer pessoa tivesse acesso a estes registros? Outro questionamento que poderia ser feito antes mesmo de seus amigos aceitarem participar do experimento é: como os dados serão utilizados e com qual finalidade? Estas perguntas são importantes porque as informações adquiridas a partir dos dados revelam gostos pessoais e padrões de comportamento dos seus amigos. E, portanto, quem tiver acesso a estes dados vai ter conhecimento sobre as preferências deles. E a forma como esta informação será utilizada é extremamente importante. Assim, temos duas observações: 1. dados são gerados a todo momento 2. dados são transformados em informações que revelam padrões desconhecidos. Por este motivo, empresas e organizações tem tanto interesse em deter dados de usuários dos seus serviços, pois isso permite conhecer o cliente a ponto de fazer ofertas que se adequem ao perfil de cada um. Mas, quais são as consequências dessa prática? Para compreender mais, vamos discutir sobre a privacidade. 1.1.2 Privacidade de dados A privacidade antes de tudo é um direito. Este direito nos resguarda da exposição de nossas informações pessoais. O contexto atual de estarmos conectados, com uma constante troca de informação, traz algumas preocupações quanto à garantia da nossa privacidade. Podemos começar citando o exemplo das publicações em redes sociais. Por meio delas, divulgamos sobre nosso local de trabalho ou estudo, quem são nossos familiares, nosso itinerário, datas importantes e tantas outras informações, na maioria das vezes sem refletir o que isto representa. E estes são os dados que nós sabemos que estamos divulgando! Além disso, os aplicativos que temos em nossos smartphones podem ter acesso à nossa câmera, microfone e contatos. Sim, ao fazer o download de um aplicativo e concordarmos com os termos de condição de uso, damos acesso à todos estes dados. Você já leu os termos de condições antes de prosseguir com a instalação de um aplicativo? Mas muito além do que publicamos, existe uma infinidade de dados que são coletados sobre nós que nem temos ideia. Eles alimentam grandes bases de dados de empresas, organizações ou instituições. Nossas preferências de lazer, política, estilo, gostos musicais, itens que compramos, informações bancárias, local de viagens, são convertidos em informações nas mãos de quem pode manipulá-los. Ficamos expostos, sendo influenciados por serviços e propagandas e, ao mesmo tempo, não temos acesso à forma que processam estes dados. Assim, sempre que abrimos nossos aplicativos, automaticamente somos direcionados a interagir com posts de conteúdos preparados para prender a nossa atenção, ou sempre existem propostas imperdíveis para adquirir itens que geralmente nos interessamos. O ponto central que deve ser levantado aqui é que podemos sim fazer uso de aplicativos, redes sociais e sites, mas devemos ter criticidade para entender que somos monitorados e possivelmente influenciados. Para refletir mais sobre a privacidade dos dados, assista ao vídeo indicado. Já ouviu o termo LGPD? Diante da problemática da privacidade e segurança dos dados, o Brasil aprovou a Lei n° 13.709/18 (Lei de Proteção de Dados - LGPD), o que vai exigir a adequação de empresas e corporações que realizam coleta, tratamento, processamento ou comércio de dados em prol de grantir a privacidade e a segurança de usuários. Isso será feito por meio de políticas e planos de proteção de dados. Ao mesmo tempo, nós usuários deveremos estar mais atentos à segurança que as empresas oferecem aos nossos dados. (Para saber mais sobre esta lei, assista ao vídeo) A rede social Facebook é um exemplo de organização que já iniciou as alterações recomendadas pela lei em busca de transparência. A Figura 1.4 exibe partes da mensagem que aparece ao realizar o acesso à página. Figura 1.4: Notificação do Facebook 1.2 O ciclo dos Dados - Construindo uma pergunta estatística No início do capítulo, definimos Ciência de Dados como um campo da ciência que realiza a transformação de dados em informação por meio de etapas. Neste tópico, vamos compreender melhor sobre cada etapa que ocorre neste processo. Primeiramente, esta série de etapas é denominada como Ciclo dos dados. A compreensão do ciclo dos dados dá uma noção geral sobre o que deverá ser realizado na metodologia de investigação, possibilitando um melhor planejamento de cada etapa. Uma vez que a Ciência de Dados busca extrair padrões para lidar com problemas, é essencial que inicialmente se tenha uma pergunta a ser respondida. Esta pergunta irá direcionar todo o nosso processo em relação à quais dados devem ser coletados, quais são os melhores métodos de análise e qual a natureza do problema. O Ciclo dos Dados compreende quatro etapas, como indicado na Figura 1.5: Figura 1.5: Etapas do ciclo de Dados Vamos lembrar do nosso exemplo inicial, cuja pergunta é: Qual gênero de filme você deve escolher para assistir com seus amigos com base nas preferências deles? Observe que geramos uma pergunta inicial que só poderá ser respondida a partir dos dados. Isto significa dizer que precisaremos coletar dados, analisá-los e, por fim, interpretá-los para tomar uma decisão. Por este motivo, esta pergunta é definida como pergunta estatística. A partir dela todas as outras etapas do ciclo dos dados serão direcionadas, a fim de respondê-la. A Figura 1.6 indica como cada etapa se desenvolve. Figura 1.6: O que fazer em cada etapa? Mas, como saber se temos uma pergunta estatística ou não? Lembre-se que uma pergunta estatística deve atender os requisitos citados no parágrafo anterior. Portanto, se eu te perguntasse: “Qual a sua idade?”, esta seria uma questão estatística? Bom, você me responderia a sua idade. Porém, não seria necessário coletar mais dados para responder a pergunta, pois apenas uma única observação já foi suficiente. Ou seja, a etapa de análise de dados não se faz necessária e por isso, não chegamos à etapa de interpretação dos dados. Por estes motivos, comprovamos que esta questão não é uma pergunta estatística, pois não indica variabilidade. Uma pergunta estatística sinaliza a variabilidade dos dados, que acontece quando existem observações que diferem da maioria registrada. Podemos adaptar a pergunta para que ela se torne uma questão estatística! No caso, poderíamos perguntar: “Qual é a idade dos estudantes do Projeto Ciência de Dados na Educação Pública?”. Ao coletar a idade de cada estudante perceberíamos que muitas se repetem, mas também há algumas que variam. Por exemplo, observamos estudantes de 11 a 15 anos. Todas as observações coletadas poderiam tranquilamente ser dispostas em um gráfico ou tabela que seriam usados para mostrar o padrão de idades da turma de estudantes do projeto. Graficamente, notamos que a maioria das idades equivale a 14 anos! Assim, todas as etapas do ciclo de dados se cumprem para responder esta pergunta. Veja a Figura 1.7 que aponta diferenças entre estes dois tipos de perguntas. Figura 1.7: Pergunta estatística e não estatística Outro conceito relevante para qualquer investigação, é que para responder a uma pergunta estatística, podemos estabelecer hipóteses, que pode ser considerada como uma suposição que será testada ao longo do processo. Esta hipótese pode estar correta, neste caso ajudando a solucionar o problema, ou pode estar incorreta. Neste caso, precisamos investigar os motivos pelos quais ela é incorreta, e pode até indicar que a nossa pergunta precisa ser melhorada. Pense no caso do nosso exemplo dos filmes, poderíamos estabelecer uma hipótese onde arriscamos dizer qual será o gênero preferido. Bom, esta hipótese será testada ao longo da investigação, e ao final, poderemos dizer se estava certa ou não. 1.3 Estruturando os dados Após definir a pergunta estatística, devemos coletar os dados e armazená-los em algum formato. Chamamos de estrutura de dados o formato em que estes dados ficam armazenados. A tabela é uma forma muito comum de se estruturar dados, embora não seja a única. Este formato é comum pois os dados ficam dispostos de uma forma organizada e de fácil entendimento. A tabela é composta por linhas e colunas. Veja como exemplo a Tabela 1: Nome Filme assistido Gênero Gabrielle Entre Realidades Drama Gabrielle Getúlio Drama Gabrielle Até que a sorte nos separe Comédia Gabrielle Terremoto: A falha de San Andreas Ação Karen A Lista de Schindler Drama Karen Férias Frustradas Comédia Karen Letra e Música Romance Karen Pantera Negra Ação Isaac Madagascar Comédia Isaac Karatê Kid Ação Isaac Um senhor estagiário Comédia Isaac A mulher de preto Terror Observe que as colunas trazem as características dos dados que coletamos. Já as linhas trazem as observações coletadas para cada pessoa, a respeito das características. Perceba que para uma mesma característica temos observações que podem ser iguais ou diferentes. Embora um mesmo Gênero possa aparecer repetidas vezes, notamos que há observações que diferem. Por isso a tabela também permite enxergar a variabilidade dos dados. No capítulo 2 este tópico será abordado de forma mais aprofundada. Além de representar os dados por meio de tabelas, você aprenderá no capítulo 3 como representar os dados de forma gráfica. Este formato permite visualizar as informações de uma forma mais clara e mais explicativa. 1.4 Identificando o tipo de problema Um grande diferencial da Ciência de Dados é a investigação sobre o que os dados revelam acerca do futuro. Portanto, esta ciência não só obtém diagnósticos sobre situações já ocorridas como também traz insights sobre o que pode acontecer (Lembra deste termo? São aquelas sacadas que comentamos no início do capítulo). A isto chamamos de predição. Parte do trabalho da Ciência de Dados é realizar predições, e para isto, existem métodos estatísticos que podem ser aplicados. Em geral, podemos dividir as situações em problemas de Regressão ou Classificação. A Figura 1.8 exemplifica estes métodos. Figura 1.8: Regressão x Classificação Você irá aprender detalhadamente como aplicar estes métodos nos capítulos 9 e 10 deste e-book. 1.5 Considerações finais Neste capítulo você foi apresentado à área de Ciência de Dados e percebeu como ela está presente no nosso dia a dia. Outro ponto relevante foi a percepção da nossa atividade enquanto consumidores e geradores de dados. Esta nova forma de gerar informações exige um conhecimento mínimo sobre como podemos ser influenciados a todo tempo. Vamos finalizar o nosso exemplo? Na tabela que constrímos, temos 4 observações para cada pessoa. Ao analisarmos quantas vezes cada gênero aparece, temos: Drama: 3 observações Comédia: 4 observações Ação: 3 observações Romance: 1 observação Terror: 1 observação Ao analisar o grupo de observações percebemos que o gênero Comédia aparece mais vezes no nosso conjunto de dados. Ao verificar a tabela, é possível notar que ele aparece pelo menos uma vez para cada pessoa. Portanto, é uma preferência comum a todo o grupo. Por isso, se você escolher um filme deste gênero sua chance de acerto será alta, concorda? A Figura 1.9 sintetiza os conceitos discutidos neste capítulo introdutório. Figura 1.9: Esquema de conceitos Viu quantos conteúdos novos você aprendeu neste capítulo? Este aprendizado vai se aprofundar mais à medida que você avançar no estudo deste e-book e tiver curiosidade em relação aos assuntos abordados! A Ciência de Dados tem revolucionado os setores onde é aplicada, pois busca constantemente obter respostas valiosas. Portanto, o cientista de dados é movido pela curiosidade! Referências Tecmundo (2018). Do futebol à medicina: a ciência de dados está em todo lugar. Disponível em: https://youtu.be/WjSimFnfPF0. Provocações Filosóficas (2018). A privacidade na internet. Diponível em: https://youtu.be/qw_TGrpPdkw. Figura 1.1: Pingado sociedade ilustrativa (2010). Adaptada de: Cidade Sustentável. Disponível em: http://www.pingado.com/imagem/0811cidade_gra.jpg. Figura 1.2: Coldplay (2011). Adaptada de: Coldplay - Viva la Vida (Live in Madrid 2011). Disponível em: https://youtu.be/9ldOuVuas1c. LGPD Brasil. Lei Geral de Proteção de Dados - Lei n° 13.709/18. Disponível em: https://www.lgpdbrasil.com.br/. Brasil. LEI Nº 13.709, DE 14 DE AGOSTO DE 2018. Lei Geral de Proteção de Dados Pessoais (LGPD). Disponível em: http://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/L13709.html. McAfee (2019). Desafios Tecnológicos para atender a LGPD. Disponível em: https://youtu.be/fuuudzh1qEo. Figura 1.5: O Ciclo de Dados. Adaptada de: Introduction to Data Science v_5.0 (IDS). Lesson 4: The Data Cycle. The Data Cycle file (LMR_1.3_Data Cycle) "],
["cap2.html", "Capítulo 2 Construindo Uma Base de Dados 2.1 O que é uma base de dados? 2.2 Como montar uma tabela 2.3 Tipos de variáveis 2.4 Como buscar base de dados abertas 2.5 Concluindo… 2.6 Você sabia? Dados, Anedotas e Fake News Referências", " Capítulo 2 Construindo Uma Base de Dados No capítulo anterior, você aprendeu sobre dados e viu, resumidamente, que a forma como os dados estão armazenados chama-se estrutura de dados. Neste capítulo vamos resgatar e aprofundar um pouco mais do que você já aprendeu de modo que você seja capaz de construir a sua própria base de dados. Mas antes, precisamos entender o que é e para que serve uma base de dados. Será que você já teve contato com alguma base de dados no decorrer de sua vida? 2.1 O que é uma base de dados? Você já ouviu falar sobre o Programa Bolsa Família? O Programa Bolsa Família (PBF) é uma política pública que visa cooperar para a inclusão social de famílias em situação de vulnerabilidade, contribuindo com alívio imediato da situação de pobreza e fome. O PBF estimula um melhor acompanhamento do atendimento do público-alvo pelos serviços de saúde, além de ajudar a superar indicadores que marcam negativamente a trajetória educacional de crianças mais pobres; como por exemplo os altos índices de evasão escolar e a repetência. Desde que foi criado em 2003, o PBF evoluiu e se tornou um dos mais eficientes mecanismos de enfrentamento a pobreza do mundo, consolidando-se como um dos maiores programas de transferência direta de renda existentes. Em todo o país, segundo dados do Ministério da Cidadania, em junho de 2020 o PBF atendia a mais de 14 milhões de famílias, das quais 180.706 mil estavam em Salvador, sendo 476.633 mil pessoas diretamente beneficiadas com o PBF na capital baiana. Interessante, né? Mas o que o bolsa família tem a ver com uma base de dados? Bem, para ser beneficiária do PBF a família precisa estar cadastrada no Cadastro Único para Programas Sociais (CadÚnico). O CadÚnico é a base de dados do governo federal onde estão registrados dados sobre famílias de baixa renda; ou seja, famílias que possuem renda mensal de até ½ salário mínimo por pessoa ou 3 salários mínimos no total. É a partir dos dados registrados no CadÚnico que é possível identificar as famílias que necessitam do bolsa família e encaminha-las para serem beneficiarias do programa. Portanto, sem uma base de dados não seria possível que uma política pública do tamanho e da importância do Programa Bolsa Família existisse. E como podemos, exatamente, definir uma base de dados? Uma base de dados é um conjunto de dados inter-relacionados (possuem relação), que estão armazenados em uma estrutura que permite que informações sejam extraídas.1 Dados são observações armazenadas. Desde imagens salvas em seu celular até vídeos presentes no youtube. Porém, sua existência não implica em significado ou sentido, logo, não tem valor algum para embasar conclusões. Por outro lado, ao organizar esse conjunto de dados com o intuito de transmitir significado, conseguimos gerar informações. Em resumo, dados podem ser considerados informações não processadas. Na base de dados da nossa discussão, o CadÚnico, dados referentes a raça, sexo, ocupação, moradia, escolaridade e muitos outros, estão relacionados a cada família que compõem o cadastro. Dessa forma, o governo consegue extrair informações referentes a habitação, saúde, educação, renda; possibilitando que se pense em formas de melhor atender as necessidades da população que compoem o cadastro. Atualmente, o CadÚnico conta com o registro dos dados de aproximadamente 29 milhões de famílias, mais de 76 milhões de pessoas. Isto é, o CadÚnico armazena dados de quase 40% da população brasileira. O CadÚnico funciona tão bem porque cumpre um requisito muito importante para bases de dados: a armazenagem eficiente dos dados. Para que a sua base de dados funcione do mesmo jeito, os seus dados precisam estar armazenados de maneira correta. Na próxima seção vamos discutir um pouco mais sobre isso. 2.2 Como montar uma tabela Vimos que em uma base de dados, os dados estão armazenados em uma estrutura que permite que informações sejam extraídas. Nessa seção, vamos entender um pouco mais sobre essas estruturas. Já aprendemos no capítulo 1 que dados são observações que foram coletadas e armazenadas de alguma forma. A maneira como esses dados são armazenados varia e algumas dessas formas de se armazenar os dados são mais eficientes que outras pois auxiliam na análise e visualização dos dados. Quanto à maneira como os dados estão armazenados podemos classificá-los de duas formas principais: estruturados e não-estruturados Os dados não-estruturados, como o nome indica, não possuem uma estrutura bem definida e previamente pensada para se armazenar os dados. Como exemplo de dados não estruturados podemos citar as redes-sociais, imagens, filmes, vídeos, músicas e documentos de texto. Figura 2.1: Exemplo de dados não-estruturados Os dados estruturados por sua vez, possuem uma estrutura bem definida, rígida e previamente pensada para se armazenar os dados. A tabela é uma das formas mais comuns e simples dessas estruturas pois nela os dados ficam dispostos em linhas e colunas que é uma forma de se armazenar dados bastante organizada e de fácil entendimento. Vamos entender mais sobre essa forma de organização. Leia o fragmento de texto abaixo extraído e adaptado do site: Cadastro Único Conhecer para incluir \"Tendo em vista o alto grau de vulnerabilidade social, alguns grupos são considerados prioritários no processo de ingresso no PBF. São eles: famílias indígenas, quilombolas, em situação de trabalho infantil, com pessoas libertas de situação análoga à de trabalho escravo e com catadores de material reciclável. No mês de junho de 2020, 5.5 mil famílias beneficiarias em Salvador pertenciam a um dos grupos denominados prioritários ao PBF. (3.0% do total de famílias beneficiarias)\" Observe agora como os dados referentes aos grupos prioritários do PBF ficam organizados em uma tabela: Figura 2.2: Grupos prioritários ao PBF em Salvador As linhas, partes horizontais da tabela, que também podemos chamar de amostras, representam indivíduos ou observações, que são os nossos objetos de estudo. No nosso exemplo, as observações são os grupos de famílias prioritárias ao PBF: “Indígenas”, “Quilombolas”, “Famílias com pessoas libertas de situação análoga à de trabalho escravo”, “Famílias com pessoas catadoras de material reciclável” e “Famílias com pessoas em situação de trabalho infantil” As colunas, parte vertical da tabela, representam atributos, ou seja, representam características referentes as observações. Em nosso exemplo, “Grupo”, “Quantidade” e “Percentual” são os atributos que caracterizam nossas observações. Note que à medida que percorremos uma linha, todos os atributos são referentes a aquela observação. Por exemplo, quando percorremos a linha cuja observação é do grupo “Indígenas”, os atributos: “Quantidade” e “Percentual” se referem a ela. No caso 5 e 0,0% respectivamente. Portanto, existem 5 famílias que fazem parte do grupo prioritário “Indígenas”, representando, aproximadamente, 0,0% do total entre todos os beneficiários do Bolsa Família em Salvador. Das mais de 180 mil famílias que recebem o Bolsa Família em Salvador, apenas 5 são famílias indígenas. Em sua opinião, por que isso acontece? Que tal buscar dados referentes a populações indígenas existentes em sua cidade? Figura 2.3: Sentido de leitura da linha Observe também que quando descemos em uma coluna da tabela, todos os valores representam a mesma característica. Por exemplo, quando descemos na coluna “Quantidade”, todos os valores representam quantidades. As quantidades variam dependendo da observação que está sendo avaliada, mas o atributo é o mesmo: Quantidade. Figura 2.4: Sentido de leitura da coluna O fato dos atributos assumirem diferentes valores, indica que os dados possuem variabilidade. Ao ler os seus dados numa tabela foi iniciada uma etapa importante da análise que permite reconhecer a variabilidade dos dados. Os atributos também são chamados de variáveis. Perceba que existe relação entre os termos variáveis e variabilidade. A palavra “variável” indica que os valores dos dados variam. Nos acompanhe na próxima seção para entender um pouco mais sobre variáveis. 2.3 Tipos de variáveis Já vimos que variáveis (atributos) são simplesmente características de nossas observações (indivíduos). Ou seja, são atributos que pertencem aos nossos objetos de estudo. Imagine que você decide estudar sobre os impactos que o Programa Bolsa Família tem sobre os hábitos e práticas alimentares dos beneficiários. Você decidiu seu objeto de estudo: famílias beneficiárias do PBF. Depois de definir o objeto de estudo, você se pergunta “Quais as informações que eu poderia levantar sobre meu objeto de estudo?”. Bem, você pode levantar muitas informações: o tipo de alimento consumido, a quantidade, se são alimentos ricos em gorduras ou em açucares, se o PBF faz com que as famílias se alimentem de maneira mais saudável, e muitas outras informações. Essas informações são os atributos do seu objeto de estudo, suas variáveis. No exemplo da seção anterior, o nosso objeto de estudo foram os grupos prioritários ao Programa Bolsa Família. E as variáveis que caracterizaram o nosso objeto de estudo foram: “Grupo”, que indica quais são esses grupos prioritários; “Quantidade”, que indica a quantidade de famílias que compõem esses grupos e “Percentual” que indica a porcentagem que esses grupos representam em relação ao total de beneficiários em Salvador. Agora que já sabemos o que são variáveis, vamos discutir sobre os seus dois principais tipos: variáveis categóricas e variáveis numéricas. 2.3.1 Variáveis Numéricas Variáveis numéricas são aquelas que assumem valores numéricos finitos ou infinitos, ou seja, são variáveis quantitativas. Essas variáveis podem ser contínuas ou discretas. As variáveis numéricas discretas são aquelas que só podem ser representadas por números inteiros. Vamos entender um pouco mais: famílias beneficiárias do PBF que tenham em sua composição gestantes, nutrizes (mães que amamentam) e crianças e adolescentes de 0 a 15 anos, recebem o benefício de R$ 41,00 para cada membro da família e cada família pode acumular até 5 benefícios por mês. Então, imagine que uma mãe que possua 5 filhos entre 0 e 15 anos irá receber o benefício de R$ 41,00 para cada filho; mas o que aconteceria se ela tivesse 5,5 filhos? Faz sentido dizer que uma pessoa tem 5,5 filhos (cinco filhos e meio)? Não, né?! Isso acontece porque a variável “Quantidade de filhos” é uma variável numérica discreta pois só pode assumir valores inteiros (0,1,2,3…). As variáveis discretas geralmente são resultado de contagens. Já as variáveis numéricas contínuas são aquelas que podem assumir valores contínuos. Ou seja, são variáveis que podem assumir qualquer valor nos números reais. Vamos retomar o exemplo acima para entendermos melhor, mas dessa vez vamos falar sobre a variável “Idade”. Para você faria sentido dizer que um dos filhos dessa mulher tem 5,5 anos (cinco anos e meio)? Sim, né?! O que estamos dizendo é que essa criança tem 5 anos e 6 meses de idade; ou quem sabe 5 anos 6 meses e 2 dias, 5 anos 6 meses 2 dias e 15 horas, e assim por diante. Isso acontece porque a variável “Idade” é uma variável contínua e pode assumir qualquer valor real. As variáveis contínuas geralmente resultam de medições. Vamos retomar o exemplo dos grupos prioritários ao PBF e ver quais foram as nossas variáveis numéricas: 2.3.2 Variáveis Categóricas Variáveis categóricas são qualitativas, finitas e expressam um valor determinado de categorias ou níveis. Ou seja, são variáveis que representam uma classificação das observações. Normalmente as variáveis categóricas representam valores que possuem palavras. Essas variáveis podem ser nominais ou ordinais. Variáveis categóricas ordinais existe uma ordenação entre as categorias. Como exemplo podemos pensar na escolaridade dos beneficiários do PBF, (1º,2º,3º grau) Variáveis categóricas nominais não possuem ordenação entre as categorias. Como exemplo podemos pensar no sexo dos beneficiários do PBF, que pode ser masculino ou feminino A variável categórica do nosso exemplo é do tipo nominal, pois não existe ordenação entre as categorias: Até aqui você já aprendeu sobre o que são bases de dados, como montar tabelas, o que são e quais os tipos de variáveis; ou seja, já apendeu o básico necessário para montar a sua própria base de dados. Na próxima seção, você vai aprender a acessar bases de dados que estão disponíveis para serem acessadas por qualquer pessoa: as bases de dados abertas. 2.4 Como buscar base de dados abertas Durante a sua jornada como cientista de dados, os dados que você irá utilizar, normalmente, estarão em bases de dados. Porém, nem todas as bases de dados estarão disponíveis para serem acessadas por todas as pessoas. Como vimos, o CadÚnico é a base de dados do governo federal onde estão registrados dados de família de baixa renda residentes no Brasil. Entre os muitos dados que estão registrados no CadÚnico, constam também a identificação de cada pessoa; informações como RG, CPF e endereço. Por conta disso, o acesso a essa base de dados é restrito. Logo, o CadÚnico não é uma base de dados aberta. Mas o que são bases de dados abertas? Antes de definirmos o que são base de dados abertas, precisamos entender o que são dados abertos. Para isso, vamos assistir o vídeo a seguir: Agora que já sabemos o que são dados abertos, podemos definir uma base de dados aberta como um conjunto de dados abertos que podem ser livremente usados, reutilizados e redistribuídos por qualquer pessoa. Na proxima seção você vai conhecer algumas bases de dados abertas que podem ser uteis para você a apartir de agora 2.4.1 Dados abertos governamentais Dados abertos governamentais são dados gerados pelo governo que estão disponíveis para serem acessados e utilizados pela população. O objetivo é aumentar a transparência, além de incentivar maior participação politica por parte do cidadão. Dados abertos da Câmara dos Deputados A Câmara dos Deputados discute e vota propostas referentes às áreas econômicas e sociais, como educação, saúde, transporte, entre outras. É também responsabilidade do Câmara dos deputados fiscalizar a utilização dos recursos arrecadados da população com o pagamento de impostos. Na base de dados da Câmara dos Deputados, você encontra dados referentes a votações, partidos políticos, informações detalhadas de deputados, entre outros. Os dados disponíveis na base de dados da Câmara dos Deputados possibilitam, inclusive, que a população crie projetos que ajudam a fiscalizar a atividade dos deputados, como por exemplo a AKAN, um aplicativo que acompanha os gastos de deputados. Figura 2.5: Dados abertos da Câmara dos Deputados Confira a seguir mais alguns exemplos de bases de dados abertas: Dados abertos do Senado Federal Dados Abertos Ministério da Justiça e Segurança Dados Abertos sobre Emprego Portal Brasileiro de Dados Abertos 2.5 Concluindo… Sem os dados, não existiria ciência de dados, e neste capítulo aprendemos um pouco mais sobre eles. No próximo capítulo, visualização e ciência de dados, vamos conversar sobre um tema essencial para futuros cientistas de dados tal como você. Mas antes, confira um breve resumo do que aprendemos: 2.6 Você sabia? Dados, Anedotas e Fake News (Seção baseada no encontro realizado com os estudantes. Prevista para ser adicionada na correção final) Referências CÂMARA DOS DEPUTADOS DO BRASIL. Papel e história da câmara. Disponível em: https://www2.camara.leg.br/a-camara/conheca/o-papel-da-camara-dos-deputados CIANCONI, Regina. Banco de Dados de acesso público. Ciência da Informação Brasília, v. 16, n. J, p. 53-59,jan./jun. 1987. NIC.br (2014). Dados Abertos para um dia a dia melhor - com narração. Disponível em: https://www.youtube.com/watch?v=T6_AsumMFm4 Programa Bolsa Família : uma década de inclusão e cidadania / organizadores: Tereza Campello, Marcelo Côrtes Neri. – Brasília : Ipea, 2013. Disponível em: https://www.ipea.gov.br/portal/index.php?option=com_content&amp;id=20408 CIANCONI, 1987, p. 54↩︎ "],
["cap3.html", "Capítulo 3 Vizualização e Ciência de Dados 3.1 Objeto de estudo 3.2 Gráfico de barra 3.3 Gráfico de tendências 3.4 Gráfico de setores 3.5 Gráfico de dispersão 3.6 Histograma 3.7 Concluindo … 3.8 Indo Além 3.9 Citações no capítulo", " Capítulo 3 Vizualização e Ciência de Dados O capítulo 2 apresenta a tabela como uma forma poderosa para estruturar e visualizar informações. No entanto, quando trabalhamos com enormes tabelas com uma imensa quantidade de linhas e colunas se torna difícil interpretar suas informações, não importa o quão organizadas elas estejam. Às vezes, é muito mais fácil interpretar essas informações através dos gráficos, conteúdo que será explorado no decorrer deste capítulo. A construção e visualização gráfica é de extrema importância na área de ciência de dados, pois é a partir de um bom gráfico que podemos extrair ideias, hipóteses e um melhor entendimento a respeito de um tema ou uma pergunta. A importância desse tipo de análise pode ser expressa por um ditado popular bastante conhecido: “Uma imagem vale mais que mil palavras”. 3.1 Objeto de estudo Para compreender a importância da análise gráfica e como utiliza-la corretamente, iremos buscar entender o perfil dos estudantes de Salvador que realizaram a prova do Exame Nacional do Ensino Médio (ENEM) no período de 2015 até 2019. Porém, antes de qualquer coisa: O que é um Perfil? Esse termo é muito usado na ciência de dados para descrever um determinado processo ou objeto de estudo através de padrões e características que o representam. Para este caso em específico, vamos analisar os estudantes da cidade de Salvador utilizando os microdados do ENEM, publicados pelo Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira (INEP), disponível ao público através deste link de acesso1. Como o termo perfil pode ser bem vasto e diversas características podem ser extraídas do nosso objeto de estudo, é necessário concentrar essa análise em perguntas mais específicas para nortear o caminho. No decorrer deste capítulo, serão exploradas graficamente as seguintes questões: A quantidade de estudantes que realizaram o ENEM aumentou de 2015 para 2019 na capital baiana? Como é a distribuição de estudantes em Salvador por cor/raça? Conseguimos identificar algum padrão para esses valores? Na dita era da informação, onde tudo está conectado, como está o acesso dos estudantes a internet em suas residências? E a computadores pessoais? O tipo de escola (pública ou privada) pode influenciar nas notas dos estudantes neste exame? A compreensão desses dados é de suma importância para entender melhor o perfil dos estudantes de Salvador que possuem o ENEM como uma oportunidade de acesso, as vezes única, ao ensino superior no Brasil. No geral, diversos setores da sociedade conseguem se beneficiar destes questionamentos: Estudantes podem buscar compreender se o tipo de escola onde estudam possui algum impacto em suas notas, enquanto gestores de políticas públicas como diretores e coordenadores podem buscar compreender as três primeiras questões para compreender melhor o panorama educacional da cidade de Salvador e assim gerar embasamento para decisões importantes no aperfeiçoamento do ensino no geral. 3.2 Gráfico de barra O Gráfico de barras é uma forma bastante comum e versátil de visualização na área de ciência de dados. Ele pode ser utilizado tanto com variáveis categóricas quanto numéricas para expressar grandezas. A Figura abaixo apresenta uma de suas utilizações: demonstrar grandezas numéricas. Figura 3.1: Número de inscritos no ENEM na capital baiana Na Figura 3.1 é apresentada a quantidade de inscritos, uma grandeza numérica, que realizaram o ENEM de 2015 até 2019 na capital baiana. É possível notar uma queda na participação dentre os períodos de 2016 até 2019. Apesar de simples e direto, a análise desse mesmo resultado através de uma tabela pode se mostrar confusa. Tabela 3.1: Número total de inscritos no ENEM em Salvador de 2015 até 2019 Ano Número total de inscritos em Salvador 2015 159835 2016 175873 2017 121063 2018 93852 2019 88557 A Tabela 3.1 mostra os mesmos dados apresentados na Figura 3.1. Note que nenhuma informação visual é passada para destacar os anos com mais ou menos participantes. Além disso, fica muito mais visível através da visualização gráfica aqueda de inscrições no ENEM de 2016 até 2019. O gráfico de barras apresenta uma característica muito importante relacionado ao tamanho das barras: elas crescem proporcionalmente de acordo as grandezas que elas se referem, ou seja, quanto maior o valor maior será sua barra. Comumente essas barras apresentam a mesma largura neste tipo de gráfico. É através da Figura 3.1 que podemos responder a primeira pergunta:“A quantidade de estudantes que realizaram o ENEM aumentou de 2015 para 2019 na capital baiana?” E a resposta é não. Apesar do número de estudantes crescer de 2015 para 2016, observa-se uma queda do número de inscritos no ENEM de Salvador, chegando a diminuir pela metade este número de 2016 para 2019. Essa resposta pode levar a novos questionamentos, por exemplo, “O que realmente motivou essa queda?”. Infelizmente encontrar a resposta para este questionamento não é trivial, requer pesquisas mais específicas a cerca do tema, o que foge do escopo deste capítulo. Todavia, é interessante refletir como a partir de um simples gráfico, podemos alcançar perguntas ainda mais complexas. Agora que respondemos a primeira questão, podemos perceber que a pergunta “Como é a distribuição de estudantes em Salvador por cor/raça? Conseguimos identificar algum padrão para esses valores?” está bastante relacionada ao seu resultado. Inicialmente para entender essa relação, precisamos entender o que seria essa distribuição de raças no questionário no ENEM. Trata-se de uma pergunta que busca entender como o estudante se classifica em relação a sua cor. Essa pergunta possui 7 respostas padrões: Não declarado Pardo Preta Branco Amarelo Indígena Opção de não apresentar tal informação Como foi explicado no Capítulo 2, esse questionamento pode ser definido como uma variável categórica dada a quantidade finita de opções apresentadas. Esta pergunta está bastante relacionada com a primeira questão, pois a quantidade total de estudantes inscritos na prova pode alterar essa distribuição, aumentando ou diminuindo a depender das categorias. Como tivemos uma diferença tão grande entre o número de inscritos em 2016 e 2019 demonstrado na Figura 3.1, uma análise mais aprofundada nesses dois anos podem trazer resultados interessantes para responder nosso segundo questionamento: Figura 3.2: Distinção de estudantes inscritos por cor/raça da cidade de Salvador para os anos de 2016 e 2019 Através da Figura 3.2, são apresentados os valores absolutos da quantidade de estudantes que realizaram o ENEM em cada ano identificados pela sua raça. Note que a grande queda encontrada na Figura 3.1 se reflete neste gráfico também: Em comparação a 2016, todas as categorias apresentaram valores menores. Por exemplo, a quantidade pessoas pardas que realizaram o ENEM caiu quase pela metade, assim como as pessoas auto-declaradas como preta. Além disso, podemos notar uma baixíssima quantidade de pessoas indígenas/amarelas que realizaram este exame e que em sua grande maioria, os estudantes da capital baiana se declaram como pardos e negros. Essa situação já era esperada e reflete uma realidade já conhecida: Segundo o Instituto Brasileiro de Estatística e Geografia (IBGE), em uma pesquisa realizada em 20172, Salvador é considerada a capital mais preta do brasil, onde 8 em cada 10 moradores se autodeclaravam de cor preta ou parda. Note que a Figura 3.2 demonstra também a principal função do gráfico de barras: dimensionar variáveis categóricas de acordo a frequência de suas categorias. Frequência para uma variável categórica pode ser definida como a quantidade de vezes que ela é representada, podendo ser dividida em dois tipos: absoluta e relativa. A frequência absoluta se trata da representação da quantidade de vezes que cada categoria ocorre. Este tipo de frequência é trabalhada na Figura 3.2, onde apresentamos a quantidade de estudantes por cor/raça que realizaram o ENEM nos anos de 2016 e 2019. Ainda na Figura 3.2, conseguimos notar que todas as categorias apresentaram uma queda na quantidade de estudantes que realizaram em 2016 para 2019, mas e se quisermos comparar este valores ainda utilizando um gráfico de barras, seria possível? Uma boa forma para comparar essas frequências absolutas distintas seria através do segundo tipo de frequência apresentada anteriormente: a frequência relativa. A frequência relativa é definida como uma proporção entre o valor que você quer estimar e o valor máximo esperado. Podemos formular este conceito da seguinte forma: \\[Frequência\\ Relativa\\ (\\%) = 100*\\frac{\\text{Valor para comparar}}{\\text{Valor máximo}}\\] Note que não foi mencionado o valor \\(100\\) presente na fórmula. Ele é apresentado para tornar o resultado da frequência relativa em porcentagem. Para compreender melhor este conceito apresentado, vamos continuar respondendo a segunda questão utilizando agora este novo aprendizado: Figura 3.3: Comparação entre os estudantes inscritos de Salvador por cor/raça para 2016 e 2019 A Figura 3.3 pode ser vista como uma extensão da Figura 3.2, utilizando a frequência relativa para apresentar uma informação implícita: a proporção dos estudantes que fizeram o ENEM em 2019 em comparação a quantidade de estudantes que realizaram em 2016. Transcrevendo a fórmula da frequência relativa apresentada anteriormente, temos: \\[Frequência\\ Relativa\\ (\\%) = 100*\\frac{\\text{estudantes que realizaram o ENEM em 2019}}{\\text{estudantes que realizaram o ENEM em 2016}}\\] Como nos é apresentada uma proporção, podemos ler o gráfico de barras apresentado na Figura 3.3 como sendo a quantidade de estudantes que fizeram a prova em 2019 em relação a quantidade que realizou a prova em 2016. Podemos identificar, por exemplo, que com exceção dos estudantes auto-declarados de cor branca todas as outras raças apresentaram uma proporção de aproximadamente 50%, ou seja, o número de estudantes pardos, pretos, amarelos, indígenas e não declarados caíram pela metade em comparação ao ano de 2016. Esta informação confirma ainda mais o resultado apresentado na Figura 3.1, mostrando que ocorreu uma grande queda na quantidade de inscrições no geral, porém isso é verificado com maior intensidade entre estudantes não declarados de cor branca na capital baiana. Através da análise do gráfico de barras conseguimos avaliar dois questionamentos de uma só vez! Porém para analisar como esses resultados ocorreram de 2016 até 2019 ao invés de dois anos separados, qual seria o melhor tipo de gráfico? Iremos explora-lo na próxima seção deste capítulo. 3.3 Gráfico de tendências Para responder com mais detalhes os dois questionamentos iniciais trazidos na seção anterior: A quantidade de estudantes que realizaram o ENEM aumentou de 2015 para 2019 na capital baiana? Como é a distribuição de estudantes em Salvador por cor/raça? Conseguimos identificar algum padrão para esses valores? Vamos usar o gráfico de tendências. Este tipo de gráfico trata a visualização de uma coleção de observações realizadas ao longo do tempo para acompanhar um evento ou processo. Por se tratar de uma coleta sequencial, ou seja, feita uma após a outra torna o fator de ordem é fundamental: importa saber se determinada observação ocorreu antes ou depois de determinado evento. Este conceito será importante para expandir as análises realizadas apenas com os anos de 2016 e 2019 para a participação dos estudantes de Salvador por cor e raça apresentadas atráves dos gráficos de barras na seção 3.2. Será através deste tipo de gráfico que podemos avaliar como essa quantidade de inscrições se comportou (aumentou ou diminuiu) de 2015 até 2019 por raça, acompanhando sua tendência. Note que realizamos este mesmo conceito no início da seção 3.2 demonstrando o número absoluto de inscrições no ENEM na capital baiana de 2015 até 2019, porém quando vamos avaliar vários anos e possibilidades de raça/cor a utilização do gráficos de barras não demonstra ser a melhor opção, pois a visualização se torna muito carregada (cheio de elementos na tela). Antes de mergulhar na análise desses dois questionamentos utilizando o gráfico de tendências é importante explorar mais um conceito novo: o plano cartesiano. Figura 3.4: Plano cartesiano simplificado A Figura 3.4 apresenta um plano cartesiano simplificado. São definidos dois eixos principais sendo eles o eixo horizontal e o eixo vertical. Cada eixo pode demonstrar o comportamento de uma variável desejada: Para o eixo horizontal, ao aumentarmos o valor se move para a direita e ao diminuir o valor se move para a esquerda, já para o eixo vertical, ao aumentarmos o valor se move para cima e ao diminuir para baixo. Ter esse conceito em mente será importante para as análises futuras. Figura 3.5: Quantidade de estudantes inscritos no ENEM na capital baiana O gráfico apresentado na Figura 3.5 fortalece ainda mais a resposta trazida para o primeiro questionamento: o número de estudantes que realizaram este exame não vem aumentando nos últimos cinco anos. É observada uma queda acentuada de 2016 para 2019. Porém através da análise dessa tendência, vemos que a maior queda ocorre de 2016 para 2017 com uma diminuição de mais de 50 mil inscrições. Esse gráfico mostra que a tendência de queda no ENEM não ocorreu de forma abrupta de 2016 para 2019, mas de forma gradual já que a partir de 2016, os valores apenas diminuiram com 2019 sendo o menor deles. Ainda neste gráfico, podemos extrair um conceito bem interessante referente a esta modalidade de visualização: o pico. O pico pode ser definido como o maior valor identificado em um determinado período. No nosso caso, o pico de inscrições no ENEM em Salvador ocorreu em 2016, pois é o maior valor verificado dentro deste intervalo de cinco anos. Figura 3.6: Tendência da quantidade de estudantes inscritos no ENEM por cor de 2015 até 2019 A Figura 3.6 é endereçada ao segundo questionamento. Podemos notar que a tendência das duas primeiras curvas, referente as cores parda e preta dos estudantes de Salvador, seguem um padrão similar ao que foi apresentado na Figura 3.5: Ocorre um pico em 2016 e a partir desse ano os valores decaem gradualmente. Porém este padrão fica bem claro para essas duas primeiras curvas, enquanto as outras se mostram aparentemente retilíneas, ou seja, não demonstram grande mudanças. Essa situação requer cuidados, pois podemos acreditar que para as outras opções não ocorreram nenhuma mudança ao decorrer do tempo. Essa divergência está relacionado a grandeza de cada curva: Valores maiores acabam esticando o gráfico, tornando valores pequenos menos representativos. Para visualizar melhor e trazer uma melhor discussão a respeito do segundo questiomento, cada curva foi separada de acordo a raça que ela representa: Figura 3.7: Tendência da quantidade de estudantes inscritos no ENEM particionado por cor de 2015 até 2019 Na Figura 3.7 conseguimos notar a diferença de grandezas que foi mencionado anteriormente ao visualizar o eixo vertical (frequência absoluta de estudantes): para a cor parda, por exemplo, é possível enxergar valores próximos de setenta e cinco mil estudantes enquanto para a cor amarela os valores ficam próximos de três mil estudantes mostrando assim uma grande disparidade. Ao separar os gráficos, cada um consegue ter sua própria escala, diferente da Figura 3.6 onde todos compartilhavam o mesmo eixo. Respondendo ao segundo questionamento, verifica-se que as raças parda, preta, amarela e as pessoas não declaradas seguem o padrão verificado dos estudantes inscritos em Salvador exposto na Figura 3.5: ocorre um pico em 2016, e a partir desse período os numéros de inscrições apenas caem. Todavía, para as pessoas de cor branca e indígena o padrão se mantém, porém difere em 2019 onde ocorre um leve aumento em comparação ao ano anterior. Esse aumento no entanto é bem diferente ao considerar a ordem de grandeza entre as raças: enquanto para cor branca esse valor aumenta em torno de doze mil estudantes, para os indígenas eles aumentam em torno de 400 estudantes, ou seja, por mais que ambas as inscrições tenham aumentado, o número de inscritos de cor branca é aproximadamente 30 vezes maior que o número de inscritos indígenas. Através dessa análise gráfica conseguimos compreender e acompanhar como o número de inscritos no ENEM em Salvador veio se alterando nos últimos anos. Essa análise poderia ser utilizada para justificar tomadas de decisão na área da educação, buscando avaliar formas de aumentar a aderência dos estudantes para se inscrever no ENEM, através de programas sociais de fomento a educação. Além disso, é importante ressaltar a importância deste exame para conseguir ingressar nas faculdades ou universidades da cidade ou país, onde em Salvador infelizmente é mostrado uma tendência de saída dos estudantes nesse exame, principalmente aqueles de cor/raça negra e parda. Essa situação apresenta ainda mais a importância de integrar esses indíviduos para compreender a causa/motivo dessa evasão na capital baiana. 3.4 Gráfico de setores Nas seções anteriores, conseguimos entender melhor o panorama dos estudantes de Salvador inscritos no ENEM nos últimos anos e como seus valores foram sendo alterados de acordo a quantidade e raça. Agora iremos avaliar o terceiro questionamento proposto no estudo de perfil: “Na dita era da informação, onde tudo está conectado, como está o acesso dos estudantes a internet em suas residências? E a computadores pessoais?”. Essa pergunta é importante, pois acredita-se que hoje tudo está conectado e que o acesso a essas ferramentas, facilitadoras do aprendizado, é algo comum a todos, mas … será? É possível que todos os estudantes do ENEM possuam fácil acesso as essas ferramentas no dias atuais? Iremos buscar responder este questionamento no decorrer deste capítulo. Para isso será apresentado uma nova modalidade gráfica: o gráfico de setores. Este gráfico, usado comumente com variáveis categóricas, apresenta sua forma mais comum equivalente ao desenho de uma “pizza”, onde cada fatia é referente a uma determinada categoria e seu tamanho é proporcional a sua representatividade. Para responder o primeiro questionamento, relacionado ao acesso da internet, vamos verificar um cenário mais atual e um cenário mais antigo, sendo respectivamente 2019 e 2015. Será que ocorreu melhorias no acesso à internet pelos estudantes do ENEM em Salvador? Figura 3.8: Porcentagem de estudantes inscritos no ENEM em Salvador com acesso a internet em 2015 e 2019 Na Figura 3.8 é apresentada a frequência relativa dos estudantes com e sem acesso a internet de acordo ao total de estudantes soteropolitanos inscritos naquele ano. O uso da frequência relativa neste caso permite uma melhor comparação entre os anos e os resultados foram positivos: Em 2015 tinhamos 72,6% estudantes com acesso a internet e esse valor aumentou para 84,7% em 2019, mostrando uma melhora de 12,1%! Essa melhora é mostrada visualmente atráves do tamanho da fatia referente a resposta “Sim” de 2015 para 2019. Este resultado pode estar associado a diversos fatores como mais acessibilidade a esta ferramenta como a redução de custos, aperfeiçoamento dos projetos sociais de inclusão digital e etc. Deixamos a cargo do leitor buscar compreender os motivos que levaram a melhora nestes resultados. Note que neste tipo de gráfico, ao utilizar frequência relativa, é necessário que a soma dos valores em todos os setores seja igual a 100%, isso não ocorre para o ano de 2015 devido a aproximação decimal utilizada de uma casa decimal. Conseguimos encontrar parte da resposta do terceiro questionamento: “Na dita era da informação, onde tudo está conectado, como está o acesso dos estudantes a internet em suas residências?” E a resposta é que o acesso dos estudantes inscritos no ENEM à internet melhorou de 2015 para 2019, mas e o acesso a computadores pessoais em suas residências? Vamos utilizar novamente os anos de 2015 e 2019 para continuar esta pergunta: Figura 3.9: Porcentagem de estudantes inscritos no ENEM em Salvador com acesso a computadores pessoais em 2015 e 2019 Na Figura 3.9 podemos verificar que o questionário do ENEM em relação a esta pergunta possui 5 respostas representativas. Todavia, diferente do acesso a internet conseguimos avaliar que a fatia referente aos estudantes que possuem pelo menos um computador pessoal diminuiu de 61,5% em 2015 para 46,1% em 2019 enquanto o número de estudantes que não possuiam nenhum computador pessoal em sua residência aumentou de 28,1% em 2015 para 43,6% em 2019. A diferença entre essas duas proporções são semelhantes: enquanto uma fatia caiu 15,4% a outra aumentou 15,5% respectivamente. Esse resultado, associado ao encontrado na Figura 3.8 pode indicar que o acesso a internet realizado pelos estudantes podem surgir de outra fonte: o telefone celular, visto a queda considerável no acesso a computadores pessoais durante o mesmo período. Ainda na Figura 3.9, podemos avaliar que algumas fatias, referentes a estudantes com mais de um computador pessoal, são menos representativas dado o seu tamanho. Essa situação indica um dos problemas ao utilizar este tipo de visualização: quando uma variável possui muitas categorias ou categorias com pouca representatividade pode dificultar a visualização das informações para o leitor. Em casos como esse uma das recomendações é a utilização dos gráficos de barras. Porém existem outras formas de melhorar essa visualização: Como vimos que as categorias mais dominantes se referem aos estudantes sem ou com pelo menos um computador em casa, vamos juntar as categorias: “Sim, dois”, “Sim, três” e “Sim, quatro ou mais” em uma só categoria: “Sim, mais de um”. Será que isso pode melhorar a visualização do gráfico anterior? Figura 3.10: Porcentagem de estudantes inscritos no ENEM em Salvador com acesso a computadores pessoais em 2015 e 2019 Na Figura 3.10 é apresentado o resultado desta alteração. A confecção dessa nova categoria permitiu encontrar uma informação implícita no gráfico anterior: a proporção de estudantes com mais de um computador pessoal em casa se manteve praticamente constante de 2015 para 2019. Isso fortalece ainda mais a narrativa de uma queda na proporção de pessoas com pelo menos um computador pessoal em casa para a proporção de pessoas sem computador pessoal. Esse tipo de informação pode ser utilizada em programas sociais ou intervenções para reverter este quadro e entender quem são as pessoas que sofrem deste tipo de necessidade digital. Neste momento o leitor pode estar se questionando: Seria possível unir os dois resultados avaliados para este questionamento, acesso à internet e computador pessoal, em um só gráfico? Abaixo é mostrado que sim, podemos. Figura 3.11: Porcentagem de estudantes inscritos no ENEM em Salvador sem acesso à internet em relação ao acesso a computadores pessoais em 2015 e 2019 Na Figura 3.11 são mostradas as proporções de estudantes de Salvador que não possuem acesso à internet em 2015 e 2019 em relação ao acesso de computador pessoal. Podemos extrair deste gráfico algumas informações: Pode existir alguma incongruência na construção dessa base de dados, pois existem estudantes com mais de um computador pessoal, porém sem acesso à internet o que pode gerar questionamentos. Essa situação pode apresentar diversos motivos e uma das hipóteses mais plausíveis seria algum erro do estudante ao responder este questionário. É possível verificar que a maioria dos estudantes sem acesso à internet também não possui computadores pessoais em casa. Esta proporção cresce de 78,8% em 2015 para 88,8% em 2019 seguido pela queda da proporção de estudantes que possui pelo menos um computador pessoal em casa. Essas informações podem indicar uma possível correlação, conceito que será estudado em capítulos futuros e de grande importância na área de ciência de dados. Assim é possível concluir o terceiro questionamento, que nessa era digital as situações melhoraram em partes: ocorreu um aumento, em termos proporcionais, de estudantes com acesso à internet, porém em contrapartida ocorreu um aumento de estudantes sem acesso a pelo menos um computador pessoal em suas residências o que pode dificultar sua navegação e uso desta ferramenta para o seu aprendizado. 3.5 Gráfico de dispersão Até o momento conseguimos observar os dados e refletir sobre três dos quatro questionamentos referente ao perfil dos estudantes de Salvador que realizaram o ENEM. Para responder o quarto questionamento: “O tipo de escola (pública ou privada) pode influenciar nas notas dos estudantes neste exame?” vamos utilizar uma nova ferramenta visual: o gráfico de dispersão. Para entender os motivos da escolha desta ferramenta precisamos antes apresentar seu conceito. Gráficos de dispersão se tratam de representações usando duas ou mais variáveis através das coordenadas cartesianas para exibir valores de um conjunto de dados. Para ficar mais claro este conceito, vamos focar em responder o quarto questionamento utilizando as notas dos estudantes de Salvador no ano de 2019, considerando apenas aqueles que: Apresentaram uma pontuação maior que zero em todas as provas, com exceção no exame de Redação Definiram o tipo de colégio no ensino médio: público ou privado Essas condições foram colocadas para evitar valores atípicos nas análises, pois apenas pessoas ausentes no exame possuem suas notas zeradas (com exceção da nota em Redação) e para focar nossa nossa análise em estudantes de escolas públicas e privadas, desconsiderando aqueles que optaram por não informar o tipo de colégio. Além disso é importante mencionar que no ano de 2019, cerca de 75% dos estudantes de Salvador não responderam a questão referente ao tipo de colégio, logo as análises apresentadas aqui representam cerca de 25% dos estudantes inscritos no ENEM 2019 na capital baiana, ou seja, 15996 estudantes no total sendo 10760 de escola pública e 5236 de escola privada. Inicialmente, será mostrado um gráfico de dispersão para as provas da área de exatas: matemática e ciências naturais, mas não se assuste! O gráfico será explicado passo a passo. Figura 3.12: Relação entre nota de Ciências Naturais e Matemática particionado pelo tipo de escola em 2019 Na Figura 3.12 são apresentadas as notas dos estudantes de Salvador em matemática no eixo vertical e no eixo horizontal as notas em ciências naturais, destacando em cores o tipo de colégio: azul escola pública e em amarelo escola privada totalizando assim três variáveis representadas em uma só imagem. Neste gráfico de dispersão são contemplados todos os estudantes que atenderam todos os requisitos expressos anteriormente, onde cada estudante é representado por um ponto de coordenada \\((x,\\ y)\\) ou se preferir \\((nota\\ em\\ ciências\\ naturais,\\ nota\\ em\\ matemática)\\). Como o ENEM funciona por pontuação, o aluno que apresentar as maiores pontuações em todas as provas possui maior vantagem na escolha de um curso superior, ou seja, os estudantes com melhor rendimento são aqueles que se aproximam do canto superior direito. Apesar desta modalidade gráfica ser bem simples, ela pode trazer resultados interessantes e intuitivos. Através da Figura 3.12 podemos verificar que a maioria dos estudantes de escolas públicas se localizam no canto inferior esquerdo, ou seja, estudantes com notas menores em ambas as provas e a medida que crescemos em ambos os eixos, mais dominante se tornam os estudantes de escolas privadas, mostrando um maior rendimento. Além desta análise, no geral é possível verificar uma tendência crescente, onde ao aumentarmos a nota de matemática vemos que a maioria dos estudantes também aumentam a nota em ciências naturais. Compreender tendências deste tipo faz parte do dia a dia do cientista de dados, pois essas tendências são as mais comuns e intuitivas na natureza. Na Figura 3.13 é apresentado dois padrões: em vermelho está uma tendência linear crescente e em azul uma tendência linear decrescente representadas em um plano cartesiano. Figura 3.13: Tendências lineares em um plano cartesiano É dito linear, pois seu comportamento lembra o formato de uma uma linha: mostra um padrão que está aumentando ou diminuindo a uma taxa constante (fixa). Os termos crescente e descrescente se referem a como os valores de um eixo se comportam em relação ao outro: na tendência linear crescente, ao aumentarmos o valor em um eixo é esperado aumentarmos também o valor no outro eixo, já na tendência linear decrescente ocorre o inverso: ao aumentarmos o valor em um dos eixos, é esperado que o valor no outro eixo decaia na mesma proporção. Na Figura 3.12 conseguimos visualizar o padrão exposto pela reta linear vermelha, ou seja, ao crescermos as notas em matemática, esperamos que cresça as notas em ciências naturais. Através da Figura 3.12 verificamos que, de certa forma, o tipo de escola que o estudante frequentou possui um fato impacto nas notas dos estudantes de Salvador, porém este padrão se repete caso seja avaliado outra prova? Figura 3.14: Relação entre nota de Linguagens e Matemática particionado pelo tipo de escola em 2019 A Figura 3.14 apresenta o gráfico de dispersão entre a nota em matemática (eixo vertical) e a nota em Linguagens (eixo horizontal) semelhante a Figura 3.12 e o padrão se repete: no geral, os estudantes de escolas públicas apresentam um rendimento inferior aos estudantes de escolas privadas. Este conhecimento é importante para ressaltar a necessidade do aperfeiçoamento das escolas públicas no município e buscar formas de reverter ou equiparar este quadro que impacta de forma negativa padrões e classes sociais, dificultando o ingresso de estudantes de escolas públicas em cursos mais concorridos como Engenharia, Direito e Medicina. 3.6 Histograma Para expandir ainda mais as discussões referentes ao quarto questionamento, vamos utilizar mais uma ferramenta gráfica de visualização: o histograma. Um histograma de um conjunto de dados numéricos se parece muito com um gráfico de barras apresentado anteriormente, embora tenha algumas diferenças importantes que examinaremos nesta seção. Figura 3.15: Histograma com as notas de matemática dos estudantes de escolas públicas e privadas de Salvador em 2019 de 300 à 1000 pontos com resolução de 50 pontos A Figura 3.15 apresenta o histograma das notas dos estudantes de escolas públicas e privadas de Salvador em matemática no ano de 2019. No eixo horizontal está representado os valores numéricos das notas dos participantes agrupados em intervalos discretos. Fazendo um paralelo com o capítulo 2, o intervalo contínuo numérico estudado foi transformado para K valores categóricos/discretos. Este valor K pode ser definido pelo usuário de duas formas: um valor inteiro, onde o algoritmo irá particionar os números em K categorias de mesmo tamanho (largura), ou através de intervalos definidos pelo próprio usuário como foi feito na Figura 3.15 onde foi são definidos limites de 50 em 50 pontos começando em 300 pontos até 1000 pontos. Você pode perceber isso ao contar a quantidade de “caixinhas” que existem no histograma. Já o eixo vertical representa a quantidade de valores que estão em cada categoria, ou seja, quanto mais valores são representados por aquela classe maior será a altura de sua barra. Caso você esteja atento, provavelmente notou uma semelhança com a frequência absoluta apresentada durante a seção do gráfico de barras. Antes de discutirmos o quarto questionamento, é importante entender que ao avaliar um histograma é preciso compreender que cada barra representa uma categoria que define um intervalo numérico limitado. Esse intervalo é na maioria das vezes apresentado da seguinte forma: \\[[limite\\ inferior,\\ limite\\ superior)\\] Onde o \\(limite\\ inferior\\) representa o menor valor contido naquela categoria e \\(limite\\ superior\\) o maior valor daquela categoria. Porém, na matemática os sinais \\([\\) e \\()\\) apresentam um significado específico, importantes para compreender a definição de uma categoria do histograma: o primeiro representa um intervalo fechado já o segundo um intervalo aberto. Juntando todo este conhecimento é possível dizer que cada K categoria em um histograma contém seu limite inferior, mas não contém seu limite superior. Em outras palavras, uma determinada barra (categoria) não representa seu limite superior, logo uma categoria começa no limite inferior e termina no superior, sem incluí-lo. Na 3.15 é possível observar que a medida que aumentamos a nota em matemática menos representativa se torna aquelas categorias, dificultando a visibilidade das barras. Além disso, o intervalo mais dominante se encontra na faixa entre 400 e 450 pontos. Caso seja desejado melhorar a resolução desses intervalos, será necessário realizar o aumento de categorias. Figura 3.16: Histograma com as notas de matemática dos estudantes de escolas públicas e privadas de Salvador em 2019 de 300 à 1000 pontos com resolução de 25 pontos Ao utilizar um espaçamento de 25 pontos como apresentado na Figura 3.16 é possível identificar como mais precisão os intervalos de notas dos estudantes da cidade de Salvador. Podemos destacar agora, através da Figura 3.16 que o intervalo mais representado é aquele que começa em 425 pontos até 450 pontos. Isso foi possível graças ao aumento da quantidade de categorias por meio da diminuição do espaçamento de 50 pontos para 25 pontos. Porém este gráfico apresenta, sem distinção, estudantes de escolas privadas e públicas, mas separando encontramos valores diferentes? Figura 3.17: Histograma com 25 categorias de notas de matemática dos estudantes de Salvador em 2019 particionado pelo tipo de escola A Figura 3.17 mostra o mesmo histograma agora com distinção entre os tipos de escola. Inicialmente verificamos que existe uma diferença na quantidade de estudantes de colégio público e privado na edição de 2019, como apontado na seção anterior. Além disso, é possível verificar que o perfil dos estudantes de colégio público é semelhante ao apresentado na Figura 3.16: O intervalo mais representativo está próximo de 450 pontos, porém e para os estudantes de escola privada os intervalos mais representativos estão em entre 600 e 700 pontos. Para uma melhor visualização e contornar o problema de diferença de escala entre os tipos de escolas, visto anteriormente na seção 3.3, vamos separar os histogramas em diferentes gráficos com seus eixos representativos próprios: Figura 3.18: Histograma com 25 categorias de notas de matemática dos estudantes de Salvador em 2019 particionado pelo tipo de escola A Figura 3.18 apresenta ambos os histogramas lado a lado com escalas de grandezas próprias. Você pode notar isso pelos valores máximos alcançados onde na escola pública foi alcançado aproximadamente 1400 em uma categoria enquanto na escola privada foi alcançado 400 em uma categoria. Ainda na Figura 3.18 é possível notar que os valores máximos de cada histogramas são bem diferentes: para escola pública, as categorias mais representativas começam em 400 pontos e vão até 475 pontos, já para as escolas privadas gira em torno de 600 a 700 pontos, apresentando assim uma diferença em torno de 200 pontos de diferença. Além disso, um fator alarmante no histograma que representa os estudantes das escolas públicas é a queda nas notas de matemática a medida que a pontuação (eixo horizontal) aumenta a partir dos 475 pontos. Este padrão também ocorre para as escolas privadas, porém para um valor superior a 700 pontos. Assim, em relação a nota de matemática, podemos dizer que a resposta para o quarto questionamento: “O tipo de escola (pública ou privada) pode influenciar nas notas dos estudantes neste exame?” apresenta uma resposta positiva, ou seja, é possível verificar uma diferença visual entre os tipos de escolas através dos histogramas discussões até o momento. Fica a cargo do leitor avaliar se o comportamento das notas de matemática no ENEM 2019 se repetem para as outras avaliações do exame. Nota: É importante ressaltar que alguns materiais trazem o conceito da densidade para o eixo vertical do histograma, porém dado o direcionamento do livro será mantido uma análise sem abordar este conceito visto sua complexidade. A ideia de densidade é importante quando é analisado histogramas com intervalos de tamanhos diferentes, mas para intervalos iguais tanto o conceito de frequência absoluta (contagem) quanto densidade funcionam para o mesmo propósito. Após concluir a leitura desta seção você pode notar a semelhança entre histograma e gráfico de barras, porém não confunda: eles são diferentes! Suas principais diferenças são: Os gráficos de barras exibem uma quantidade por categoria. Eles são frequentemente usados para exibir as distribuições de variáveis categóricas. Os histogramas exibem as distribuições de variáveis numéricas. Todas as barras em um gráfico de barras têm a mesma largura e há uma quantidade igual de espaço entre as barras consecutivas. As barras de um histograma podem ter larguras diferentes e são contíguas. 3.7 Concluindo … Através deste capítulo conseguimos entender como a visualição gráfica pode trazer diferentes ideias e esclarecimentos a respeito dos nossos questionamentos, apresentando informações de forma simples e de fácil entendimento. Vimos também que cada gráfico pode trazer uma visão distinta e cabe ao leitor saber escolher qual a melhor abordagem a partir da sua pergunta e conjuntos de dados. Nosso questionamento sobre o perfil dos estudantes de Salvador que realizaram o ENEM conseguiu apresentar diversos insights, porém desanimadores. Na Figura 3.19 é apresentado o infográfico resumindo as informações extraídas a partir da análise gráfica. Figura 3.19: Infográfico dos resultados encontrados para o nosso questionamento Esses resultados são desanimadores, pois no geral mostra uma grande evasão no número de inscritos de estudantes de vulnerabilidade social e um baixo rendimento dos estudantes de escolas públicas em comparação aos de escola privada. Todavia, para confirmar esses resultados apenas a visualização gráfica é insuficiente: Na ciência de dados precisamos de indicadores e medidas matemáticas para expressar se de nossas hipóteses são verídicas. Esse ferramental será explorado nos próximos capítulos deste livro, então mantenha o estudo! 3.8 Indo Além Fizemos diversas análises e respondemos alguns questionamentos a respeito do perfil dos estudantes de Salvador que realizaram o ENEM não foi? Porém com a riqueza que esta base de dados possui o leitor pode explorar ainda mais! Utilizando Python, explicada em nosso capítulo de programação, você conseguiria ir além e responder os seguintes questionamentos? Através do infográfico na Figura 3.19 avaliamos que ocorreu um aumento no número de estudantes sem acesso a computadores pessoais no ENEM de 2015 para 2019, o que pode dificultar os estudos desta parcela de estudantes. Você consegue avaliar a distribuição de cor/raça para esses estudantes em 2019 utilizando o gráfico de barras? Na seção 3.6 verificamos que, infelizmente, na edição de 2019 do ENEM as notas dos estudantes de escolas públicas são menores em comparação aos estudantes de escolas privadas para a prova de Matemática. Utilizando o histograma, você consegue avaliar se este padrão se repete para as notas de Linguagens nesta mesma edição? 3.9 Citações no capítulo [1] Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira. Microdados Exame Nacional do Ensino Médio. Disponível em: link de acesso [2] Acorda Cidade. IBGE-BA: Salvador é a capital mais negra do Brasil e com a maior desigualdade salarial entre brancos e pretos. Publicado em 19 de novembro de 2018. Disponível em: link de acesso "],
["cap4.html", "Capítulo 4 Correlação e Causalidade 4.1 O que é correlação? 4.2 Quão forte é a correlação? 4.3 Relações de causa e efeito: conhecendo a causalidade 4.4 Correlações expúrias 4.5 Considerações Finais 4.6 Indo além Referências", " Capítulo 4 Correlação e Causalidade Sempre buscamos saber o que leva um fato a ocorrer, não é mesmo? A Figura 4.1 abaixo trás alguns tipos de questionamentos que fazem parte da nossa vida. Figura 4.1: Questionamentos Além destes exemplos, mas em diversas situações cotidianas atribuímos causas a fatos que nem sempre condizem à realidade e, mais precisamente, sem respaldo estatístico. Isto porquê, nossa mente sempre busca encontrar padrões, ainda que eles não existam. Portanto, neste capítulo vamos aprender os conceitos: Correlação e Causalidade. Não basta conhecer estes termos, é preciso saber interpretá-los. Por isto, a partir de agora vamos iniciar uma discussão super interessante que irá nos ajudar neste aprendizado! Para compreender estes conceitos, vamos utilizar dados voltados ao desempenho de atletas. Desta forma, poderemos analisar quais variáveis se relacionam com resultados das provas realizadas. A base de dados utilizada foi adaptada da plataforma kaggle. 4.1 O que é correlação? Dizemos que há correlação, quando verifica-se uma relação de associação entre duas variáveis! Neste caso, é possível verificar para as duas variáveis, ao mesmo tempo, uma tendência no comportamento. Para entender melhor, imagine que estamos avaliando se pessoas com maior massa corporal (kg) consomem mais água durante o dia. Caso esta hipótese seja confirmada, significa que a depender da massa corporal do indivíduo, a quantidade de água ingerida irá variar. Assim acontece em outros casos, o estudo de correlação busca descobrir se variações em uma característica se associa à variações em outra característica. Vamos iniciar com um estudo de caso. Queremos saber quais variáveis estão associadas a pontuação total em partidas de vôlei. Esta condição é definida pelas variáveis “Ranking All”, que trata a pontuação de todos os anos e “Ranking 2020”, que trata do ano 2020. Observe na Figura 4.2 as variáveis que possuímos. Perceba que existem variáveis numéricas e também categóricas. Figura 4.2: Trecho de base de dados utilizada Para seguir a convenção estatística, denominamos “Ranking Geral” e “Ranking 2020” como variável resposta ou dependente ou ainda, variável Y. O comportamento delas pode estar associado à alterações de outras variáveis da tabela. Assim, estas duas variáveis são as respostas que queremos avaliar na nossa análise. O restante das variáveis são denominadas variável independente, variável X, pois é a partir das variações delas é que poderemos avaliar as respostas na saída. Ao verificar a parte dos dados exibida na Figura 4.1, sem qualquer informação prévia, qual destas variáveis você acredita que mais influencia o Ranking? Pesquisando na literatura, vemos que estudos de correlação foram realizados em jogadores de vôlei. Variáveis diferentes foram avaliadas, mas no final, fica claro a importância deste conteúdo para gerar melhorias e estratégias de treino. Um estudo de Crivelin et al., 2015 indicou alta correlação entre a composição corporal de jogadores (variável X) e a altura do salto em cm (variável Y). Outro estudo (de Marques Junior, 2015) investigou os fundamentos do vôlei que geram pontos ao longo de uma partida. Assim, foi indicada uma alta correlação entre o ataque, bloqueio e saque (nesta ordem) para a realização de pontuação. A Correlação (ou Associação) pode ser definida pelo seu sentido e ser vizualizada em um Diagrama de dispersão. Assim, ocorrem três formas distintas de correlação: Figura 4.3: Tipos de correlação 4.2 Quão forte é a correlação? Além do sentido, uma forma de melhor entender a correlação é através da análise do grau ou intensidade que ocorre. Esta força, ou intensidade é avaliada a partir do coeficiente de correlação, um valor numérico que indica o grau e a direção da tendência de associação entre as variáveis. Vamos comentar duas formas de cálculo do Coeficiente de Correlação. Todavia, é importante você saber que existem outras formas e escolher aplicá-los irá depender das características verificadas na sua amostra. 4.2.1 Coeficiente de Pearson Este coeficiente é representado pela letra r e também pode ser chamado de correlação linear ou r de Pearson. Seus valores se situam entre -1 e +1, e a interpretação ocorre da forma indicada na Figura 4.4. Se a correlação é 0, significa que não há associação entre as variáveis. Quando o valor do r de Pearson é 1, independente do sentido, dizemos que esta correlação é perfeita, é a mais forte possível. Quanto mais próximo de zero, menor é a correlação. Vale lembrar que este coeficiente expressa o grau de associação entre duas variáveis quantitativas. Figura 4.4: Coeficiente de Pearson É comum optarmos por verificar o grau de associação por meio de uma Matriz de correlação. Observe a Figura 4.5, que representa a matriz de correlação dos dados estudados. Figura 4.5: Matriz de correlação - Pearson Sabendo que estamos avaliando quais fatores podem influenciar a posição de um país no Rankin geral ou no Ranking de 2020, localize nesta tabela as linhas que indicam a associação entre estas duas variáveis com todas as outras. Observe que para a variável reposta Ranking geral, as variáveis Ranking em 2020, Idade e Peso (kg) são as que apresentam maior grau de associação. Já para o Ranking em 2020, as variáveis que apresentam maior grau de associação são Ranking geral, Peso e Pontos. Que tal visualizar esta matriz em forma gráfica? Veja a Figura 4.6 e tente entender as informações. Figura 4.6: Gráfico - Matriz de correlação Esta forma de representação é bastante completa. Isto porque utiliza cores e também adiciona o valor numérico do cálculo do correlação entre as variáveis. A esta altura você já deve ter percebido que a coloração vermelha indica valores de correlação positivos, enquanto as tonalidades em azul indicam os valores negativos. A intensidade das cores indica a força da correlação. Ou seja, quanto mais próximo de 1 for o valor de r, mais forte será a tonalidade. Localize a variável “Ranking geral” e veja sua associação com as variáveis restantes. Percebemos que seu grau de associação com a variável “Ranking em 2020” é 0,5, por isso a tonalidade indicada na caixa é em tom vermelho. Já com a variável Idade a correlação é -0,6, com tonalidade azul. Este valor negativo indica que quanto maior a idade das jogadoras, menor as notas no ranking geral. Esta informação é relevante, uma vez que a Idade influencia o desempenho de atletas e é um dos principais fatores que levam à aposentadoria destes profissionais (Agresta et al., 2008. Observe também que a correlação com as outras variáveis tem sentido negativo e são bastante fracas, se aproximando de zero. Desta forma, podemos dizer que estas variáveis praticamente não são relacionadas a Ranking geral. O mesmo pode-se dizer quanto ao Ranking em 2020. Vale destacar que a correlação de uma variável com ela mesma sempre será 1. Também podemos optar por visualizar a correlação separadamente. Assim, comparamos apenas a variável dependente versus a variável independente. Verifique graficamente a associação entre Pontos (variável de entrada) e Raking Geral (variável de saída). Figura 4.7: Associação entre Pontos e Ranking geral Ao observar este gráfico, não percebemos uma tendência, um comportamento que indique associação entre estas variáveis. As observações estão dispersas pelo gráfico, não indicando um padrão associativo e a reta plotada praticamente não tem inclinação. Verifique agora a associação de Pontos com Ranking 2020. Figura 4.8: Associação entre Pontos e Ranking em 2020 Ocorre a mesma situação anterior, o que indica que Ranking 2020 também não se associa com Points. Ou seja, mesmo que a variável Points sofra variações, isto não irá interferir em Ranking All ou Ranking 2020. Já sabemos que o valor 0 indica que não há correlação, e que o valor de 1 indica o maior grau desta estatística. Mas, como classificar os outros valores encontrados? Observe a Figura 4.9 abaixo: Figura 4.9: Hieraquia de valores - Correlação 4.2.2 Coeficiente de Spearman Assim como o r de Pearson, esta métrica também se situa entre -1 e 1. A diferença é que neste caso não existe a obrigatoriedade de haver relação linear entre as variáveis. Deste modo, este coeficente avalia se as variáveis apresentam uma relação, mas a mudança delas não necessariamente precisa ser a uma mesma taxa. Veja a Figura 4.10 com a matriz de correlação para o Coeficiente de Spearman. Figura 4.10: Correlação de Spearman Observamos que alguns valores se diferenciam daqueles apresentados pela correlação de Pearson na 4.3. Apesar destas variáveis terem um baixo/ moderado grau de associação, ao se utilizar a correlação de Spearman nota-se para algumas delas (Salto (cm), Pontos e Bloqueio (cm)) um coeficiente de correlação maior do que o obtido pela correlação de Pearson, indicando que o relacionamento entre elas não necessariamente é linear. Por isto a diferença de valores apresentada na Figura 4.11. Figura 4.11: Comparação Spearman e Pearson Correlações categóricas Até agora utilizamos apenas dados numéricos para quantificar a correlação. Mas, e quanto às informações categóricas que possuímos, elas devem ser desconsideradas? A resposta é não. Existem formas de se avaliar o grau de associação de variáveis qualitativas, como: qui-quadrado, coeficiente phi, V de cramer e outras. 4.2.3 Multicolinearidade Quando observamos todas as linhas e colunas da matriz de correlação, percebemos que outras variáveis (variáveis de entrada), também apresentam um valor de correlação. Isto indica que elas apresentam uma relação entre si. Veja na figura que existe um grupo de variáveis de entrada com altos valores de correlação positiva. Peso, Spike e Block! Isto significa que estas variáveis tem uma interação entre si. Quando isto ocorre dizemos que há multicolinearidade. Podemos visualizar este comportamento de forma gráfica. Observe na Figura 4.12, a plotagem entre estas variáveis e observe a tendência entre elas. Figura 4.12: Associação entre variáveis independentes Basicamente, percebemos que os pontos estão dispersos, porém, apresentam uma tendência crescente em todos os gráficos. Isto possibilita até mesmo traçar uma linha de tendência para observarmos melhor. Assim, precebemos associação linear crescente entre Altura e peso; altura e salto; peso e salto. Em geral, espera-se que em um conjunto, as variáveis de entrada praticamente não apresentem correlação entre si e apenas se associem à variável de saída. Isto porque, a multicolinearidade pode nos confundir quanto ao comportamento observado na variável resposta. 4.2.4 Considerações sobre a análise Verificamos que a relação de associação das variáveis avaliadas é muito baixa em relação às variáveis dependentes (Ranking 2020 e Ranking geral). Vale ressaltar que aplicamos métodos que consideram variáveis numéricas e, portanto, não avaliamos as variáveis categóricas. Assim, é possível que estas variáveis tenham uma maior relação com os resultados de Ranking. 4.3 Relações de causa e efeito: conhecendo a causalidade De acordo com o dicionário, a palavra “causalidade” se refere à condição ou qualidade do que é causal, do que produz efeito. É uma relação direta entre causa-efeito.Veja estas frases e reflita sobre a mensagem que você compreende. div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;} Pare o aquecimento global: se torne um pirata Habilidades em linguagens reduzem ataques de raiva na pré escola Qual a causa de câncer? chocolate faz bem? Observe que estas frases passam uma relação imediata de causa e efeito entre as variáveis. Em “a”, dá a entender que é possível parar o aquecimento global ao se tornar um pirata. Mas, será que estas alegações fazem sentido? Uma relação de causa-efeito pode ser descrita por meio de palavras como impacta, afeta ou efeito. Deste modo, este tipo de relação sugere que duas variáveis não apenas aparecem juntas, mas que o fato de uma delas ocorrer automaticamente causa o surgimento da outra. Observe este outro exemplo: Em países do hemisfério norte as pessoas gastam mais em compras no frio. À primeira vista, tendemos a achar que o frio provoca um aumento nas vendas. Porém, se pensarmos um pouco vamos perceber que datas festivas como Natal e Ano Novo nestes países, ocorrem no inverno. Portanto, esta pode ser a causa do aumento das compras. Ou seja, não podemos simplesmente atribuir uma relação de causa e efeito a um evento, pois podem haver muitos fatores que influenciam este contexto. 4.3.1 Coincidência ou Causalidade? A única forma de provar uma causalidade é a partir de uma análise detalhada dos dados. Estas análises são realizadas por meio de estudos observacionais ou estudos experimentais aleatório, em um grupo de indivíduos divididos em: grupo controle e grupo de tratamento. Este último sofre intervenção por algum fator que se deseja analisar. Estes grupos são monitorados às mesmas condições, e a diferença nas respostas finais são computadas. Uma questão central para respondermos é se de fato o tratamento aplicado produz em efeito na resposta obtida. Caso isto ocorra, a associação é causal. Observe que quando investigamos a causalidade, não queremos saber apenas se há uma associação entre variáveis. Mas sim, se esta relação implica diretamente causa-efeito. Desta forma, afirmar a ocorrência de causalidade exige duas etapas: 1 - Observar uma associação entre variáveis 2 - Análise cuidadosa de causalidade Algumas situação não permitem a realização de experimentos aleatórios, ainda que seja para verificar a causalidade. Por exemplo, se qusiermos avaliar a os efeitos do consumo de ácool durante a gravidez, deveríamos convidr algumas grávidas para o nosso experimento. Mas, isto seria sensato? Em situações deste tipo, deve ser realizado um estudo observacional. Se o grupo de tratamento e o grupo de controle apresentarem diferenças além do tratamento aplicado, tomar conclusões sobre a causalidade se torna algo difícil. Neste caso, chamamos esta diferença de fator de confusão. Vamos entender melhor a partir de um exemplo. Nos anos 60, alguns estudos apontaram que pessoas que ingeriam café tinham altas taxas de câncer de pulmão se comparadas às que não ingeriam. Devido a isto, algumas pessoas começaram a atribuir o café como causa de câncer de pulmão. Porém, hoje sabemos que café não é a causa desta doença! Na verdade, esta análise tinha um fator de confusão: o hábito de fumar. Naquela época, pessoas que ingeriam café provavekmente também tinham o hábito de fumar. E esta prática sim, causa câncer de pulmão. Então, podemos concluir que: o consumo de café estava associado ao cancer de pulmão, porém não é o causador da doença! Bom, os fatores de confusão são bastantes comuns. Mas estudos confiáveis tomam bastante cuidado para reduzir esta confusão e saber o quanto ela afeta a análise. 4.4 Correlações expúrias Bom, já aprendemos o conceito de correlação e também sabemos que a correção não implica causalidade. Veja a Figura 4.13 e avalie a tendência entre afogamentos e aparições do ator Nicholas Cage em filmes. Figura 4.13: Afogamentos e aparições do Nicholas Cage A associação entre estas variáveis é nítida, não é mesmo? Portanto, claro que elas são correlacionadas (r = 0,666) e mais, a causa dos afogamentos é a aparição do Nicholas Cage em filmes! Claramente esta afirmação está ERRADA!! Assim como muitas outras afirmações que ouvimos no nosso dia a dia que são bastante questionáveis, esta afirmação reflete uma certa negligência à compreensão de Correlação e Causalidade.Ainda que esta relação seja visível graficamente, o nosso senso crítico precisa prevalecer, caso contrário seguiremos acreditando em informações dúbias e tomando decisões incorretas. Para não sermos reféns deste tipo de conclusão, precisamos saber de dois fatores que acarretam esta conclusão errônea: 1 - o primeiro deles é o já citado fator de confusão: ou uma terceira variável que afeta o resultado, que não está sendo considerada. 2 - Acaso: sim, coincidências acontecem e precisamos ter criticidade para avaliar se a informação é lógica. Uma crítica semelhante pode ser feita ao caso seguinte. Em alguns meses do ano, foi observado que o número de afogamentos aumenta. Ao mesmo tempo, as vendas de sorvete também aumentam! Antes de você refletir, vamos a mais informações. Os meses recorde de afogamentos e vendas de sorvete são Dezembro e Janeiro. Segundo os dados estas variáveis estão correlacionadas positivamente, com um r = 0,98. E mais do que isso, será que poderíamos concluir que as vendas de sorvete causam afogamentos? Errado. Temos uma terceira variável em comum a estas duas, a Temperatura. Em dias mais quentes as pessoas vão à praia, ou tomam sorvete, e com isso, mais pessoas ficam expostas à chances de afogamento. Portanto, neste problema deve ser levado em conta a Temperatura, que está associada aos afogamentos e às vendas de sorvete. 4.5 Considerações Finais Neste capítulo, aprendemos a avaliar afirmações, com embasamento estatístico. A Figura 4.14 exibe um mapa conceitual do que foi discutido. Figura 4.14: Mapa conceitual do capítulo 4 O que achou do tema deste capítulo? Com certeza, a partir de hoje você será muito mais crítico ao ler ou ouvir uma informação. É exatamente isto que buscamos, ter um senso crítico em relação às informações que nos chegam e conhecer formas que garantam que elas sejam corretas! 4.6 Indo além Em progresso Referências [1]https://www.tylervigen.com/spurious-correlations: Correlações espúrias [2]https://www.inferentialthinking.com/chapters/intro.html: Inferential Thinking. Causality and Experiments. UC Berkeley. [3]https://curriculum.idsucla.org/table/ : IDS Curriculum v5_0 "],
["cap5.html", "Capítulo 5 Indicadores Básicos na Ciência de Dados 5.1 Objeto de estudo 5.2 Medidas de tendência central 5.3 Medidas de dispersão 5.4 Diagramas de Caixa 5.5 Concluindo … 5.6 Indo Além 5.7 Citações no capítulo", " Capítulo 5 Indicadores Básicos na Ciência de Dados Apesar da ciência de dados ser bem conhecida atualmente através das aplicações mais práticas e incríveis da Inteligência Artificial como demonstrado no vídeo abaixo: Ela está presente de outras formas no dia a dia do brasileiro de forma sutil. Na Figura 5.1 destacamos alguns termos desta área, consegue identificá-los? Figura 5.1: Manchetes de jornais com termos da ciência de dados Eles são muito recorrentes neste imenso universo que é a ciência de dados e seus conceitos são bem simples de entender além de práticos! Porém, você pode estar se questionando “Porque devo aprender mais sobre eles?” ou “Vou usar isso em algum momento da minha vida?”. Questões como essas podem ser recorrentes durante a aprendizagem e são importante serem endereçadas. A área que é apresentada na Figura 5.1 e que será discutida neste capítulo é chamada de estatística descritiva. Ao estudar os dados, é comum o cientista buscar padrões desconhecidos e quantificar grandes quantidades de números em um só valor e é neste aspecto que esta ferramenta simples e eficaz é aplicada. O nome pode parecer complicado, porém se trata de um ramo da matemática com uma série de técnicas para descrever e resumir dados ou informações em indicadores de fácil compreensão. Essa área pode ser dividida em três grupos de medidas: tendência central, dispersão e forma. Neste capítulo focaremos nas duas primeiras. Além disso iremos explorar formas de visualizações utilizando estes conceitos como o diagrama de caixas e distribuições. 5.1 Objeto de estudo Para compreender a importância dessas medidas estatísticas e como usá-las, vamos estudar os dados de segurança pública da cidade de Salvador disponibilizados pela Secretaria de Segurança Pública (SSP) no portal1 para compreender um pouco da realidade que Salvador convive: a violência. Porém, antes de apresentar nosso tema central de estudo precisamos entender como funciona essa base de informações. Disponibilizados através de boletins mensais, as ocorrências dos principais delitos na capital baiana são separados por áreas e regiões. Os principais tipos de delitos considerados são: Homicídio Doloso Lesão Corporal Seguida de Morte Roubo com Resultado Morte (Latrocínio) Tentativa de Homicídio Estupro Roubo a Ônibus (Urbano e em Rodovia) Roubo de Veículo Furto de Veículo Uso/Porte de Substância Entorpecentes (Usuários) Você viu que eu citei “áreas” e “regiões” certo? Elas são definidas pela SSP em Salvador respectivamente como Área Integrada de Segurança Pública (AISP) e Região Integrada de Segurança Pública (RISP). Para entender melhor essas divisões, vamos explicar através da Figura 5.2 estes conceitos usando uma abordagem de conjuntos. Figura 5.2: Conceito por trás das divisões AISP e RISP AISP são conjuntos de bairros, ou seja, cada AISP representa uma quantidade de bairros da cidade. Já RISP se trata de um conjunto de AISP e finalmente, o conjunto total de RISP representa toda a extensão da cidade de Salvador. Essa divisão é realizada para facilitar o trabalho dos profissionais de segurança em compreender como cada região se comporta de acordo a um determinado tipo de delito, além de agrupar melhor os bairros, que somam um valor superior a 160 em Salvador. Imagina como seria mais complexo de apresentar um plano para cada bairro em específico para um gestor municipal ou estadual? Figura 5.3: RISP Atlântico de Salvador realizado pela SSP Figura 5.4: RISP Baía de Todos os Santos (BTS) de Salvador realizado pela SSP Figura 5.5: RISP Central de Salvador realizado pela SSP As Figuras 5.3, 5.4 e 5.5 mostram as divisões referentes as AISP e RISP em Salvador. Para contextualizar, a maioria das escolas que participaram do projeto “Meninas na Ciência de Dados” são localizadas no bairro da federação e este bairro está contido na AISP - Rio Vermelho que, por sua vez, está contida na RISP - Atlântico. Com toda estas informações em mente como os principais tipos delitos, divisões e subdivisões territoriais de Salvador determinada pela SSP podemos de fato identificar um objeto de estudo com um propósito: entender um pouco a violência em Salvador. Será analisado em específico um tipo de delito principal nos meses de janeiro, feveireiro e março de 2019 em Salvador: Roubo a Ônibus urbano e em rodovia. Essas escolhas não foram aleatórias. Os três meses citados foram escolhidos por ser um período de grande movimentação na capital: estação de verão, um dos principais períodos para turismo em Salvador,onde a grande maioria dos trabalhadores entram de férias. Além disso o delito de roubo a ônibus é uma realidade presente para quem depende do serviço público para se locomover na capital baiana, seja a trabalho, estudos ou a lazer. Figura 5.6: Manchetes sobre roubos a ônibus na cidade de Salvador Na Figura 5.6 podemos verificar uma realidade referente a este crime: em média ocorreram 3 assaltos em Salvador por dia avaliados durante 2019. Neste capítulo frases como essa serão compreendidas por vocês de forma mais simples e intuitiva! A base de dados referente aos assaltos à coletivos na cidade de Salvador na estação do verão em 2019 é apresentada abaixo: Tabela 5.1: Ocorrências registradas na cidade de Salvador no período de Janeiro à Março em 2019 RISP AISP Janeiro Fevereiro Março Atlântico Brotas 17 6 16 Atlântico Rio Vermelho 7 10 5 Atlântico Boca do Rio 5 1 7 Atlântico Itapuã 17 11 8 Atlântico Barra 2 2 1 Atlântico Nordeste 4 1 6 Atlântico Pituba 13 8 4 BTS Barris 17 5 10 BTS Liberdade 8 8 11 BTS Bonfim 8 12 12 BTS São Caetano 22 15 16 BTS Periperi 13 11 20 BTS CIA 1 1 2 Central Pau da Lima 5 4 9 Central Tancredo Neves 40 25 33 Central Cajazeiras 11 9 6 Na Tabela 5.1 vemos valores para cada uma das regiões divididas pela Secretária de Segurança Pública que serão estudados no decorrer deste capítulo. Alguns valores são bem alarmantes como a AISP de Tancredo Neves com um total de 40 ocorrências de assalto à coletivos em janeiro e 33 em março. Em contrapartida, outras AISP como Barra e CIA apresentam valores muito baixos em comparação com 1 ou 2 ocorrências. Porém, e se quisermos resumir esses valores para gerar indicadores para uma determinada região (RISP) ou para a cidade neste período? Como esses indicadores poderiam ajudar os gestores a entender como está determinada região ou área em relação ao aumento da violência, considerando este delito? E principalmente: Como podemos visualizar e passar estas ideias de forma fácil e intuitiva para gerar ações públicas de combate? Para responder esses e outros questionamentos, vamos estudar alguns conceitos importantes da ciência de dados como medidas de tendência central, medidas de dispersão, diagrama de caixas e distribuição no decorrer deste capítulo. 5.2 Medidas de tendência central As medidas de tendência central são aquelas que buscam refletir o ponto de equilíbrio dos dados, ou seja, o seu ponto central. Diversas medidas existem com esse intuito e as mais básicas são: média, mediana e moda. Porém você pode se perguntar “Porque existe mais de uma medida se elas apresentam o mesmo significado?” Bom, cada uma dessas medidas possui suas vantagens e desvantagens, onde entendê-las pode ser fundamental para compreender aquele conjunto de informações da forma mais coerente com a realidade2. Porém, antes de cair de cabeça nestas medidas vamos avaliar a Tabela apresentada na seção anterior (número de ocorrências de roubo à ônibus) através de um mapa de calor. Na Figura 5.7 apresentamos um mapa de calor para todas as áreas de Salvador considerando o número de ocorrências, onde quanto mais avermelhada for aquela região, maior é a incidência de delitos e quanto menor for o número de ocorrências mais branca se torna a célula. Figura 5.7: Mapa de calor da incidência de roubos à ônibus nas áreas de Salvador Apesar do mapa de calor parecer bastante com uma tabela na Figura 5.7, existe uma diferença: Cada célula (campo do gráfico) apresenta uma coloração de acordo a grandeza representada. Além disso podemos verificar que o setor Tancredo Neves, localizado na RISP Central, apresenta os maiores valores disparado, enquanto o restante em sua grande maioria aparece com um tom mais rosa. Em contrapartida as áreas Barra e CIA apresentam os menores números de ocorrências, não passando de duas ocorrências por mês. Visualmente falando, já conseguimos extrair algumas informações deste gráfico não é? Em geral percebemos que: O setor com maior incidência é, de forma disparada, Tancredo Neves em todos os meses do verão. Barra e CIA são os setores com os menores números de ocorrência. Somando o número total de ocorrências por área para cada mês encontramos para janeiro, fevereiro e março respectivamente 190, 129 e 166 ocorrências. Logo, o mês de Janeiro se destaca inicialmente em nossa análise. Além dessas informações, você consegue extrair mais conhecimento deste gráfico? Apesar da Figura 5.7 apresentar um panorama completo das ocorrências, podemos notar um detalhe curioso: O fato da área Tancredo Neves apresentar altas incidências, torna outros setores, visualmente, menos perigosos. E se fizermos uma análise por região, será que conseguiremos identificar novas zonas com alta incidência de assaltos? Na Figura 5.8 apresentamos novamente o mapa de calor, agora separado por regiões. Figura 5.8: Mapa de calor particionado por regiões de Salvador Cada uma das três regiões apresentaram características interessantes no verão: Na região Atlântico podemos verificar que as áreas Brotas e Itapuã são as mais perigosas de modo geral, onde em Janeiro ocorreu em ambas o maior número de ocorrências com 17 casos. Além disso, Pituba e Rio Vermelho possuem um grande tom de rosa, mostrando que elas não são tão seguras. Na região BTS nota-se que diversas áreas apresentam tons avermelhados, mostrando um grande perigo nesta região com destaque para São Caetano e Periperi que apresentam os maiores valores. Na região Central é possível perceber que a área Tancredo Neves é a mais perigosa, mantendo o mesmo padrão apresentado na Figura 5.8. Com esta nova análise conseguimos perceber que as vezes até uma imagem podem acabar nos enganando no que se refere a perspectiva: Na Figura 5.7 apenas a área de Tancredo Neves se destacava em comparação as outras, porém ao fazer uma análise mais aprofundada, considerando uma comparação apenas dentro das regiões definidas pela SSP, verificamos que outras áreas apresentam uma grande quantidade de ocorrências. Este padrão será observado nesta seção quando avaliarmos as medidas de tendência central, onde vamos entender o impacto de um valor aberrante. A primeira medida de tendência central a ser analisada será a Média. Trata-se da medida mais conhecida e usada em nosso dia a dia, como vimos no início deste capítulo. Ela é calculada através do somatório de todos os valores dividido pela sua quantidade. Com este conhecimento em mãos vamos montar uma tabela da média de ocorrência para os meses do verão de acordo a região: Tabela 5.2: Médias encontradas para as ocorrências de assalto à ônibus separada por região RISP Janeiro Fevereiro Março Atlântico 9,29 5,57 6,71 BTS 11,50 8,67 11,83 Central 18,67 12,67 16,00 Porém, antes de analisar a Tabela 5.2, por quê calculamos a média? Bom, o intuito é apresentar um indicador para o número de ocorrências para as regiões de Salvador encontrando uma medida capaz de resumir todos os valores daquelas áreas. Assim, ao invés de avaliar área por área, temos um valor único que resume aquela imensa quantidade de dados em um só representativo. Através das médias calculadas na Tabela 5.2, podemos perceber que: O mês de fevereiro como um todo possui os menores índices de ocorrências em comparação a janeiro e fevereiro. A RISP Central possui as maiores médias de ocorrências nos meses de verão, mesmo sendo uma região com apenas 3 áreas catalogadas. Note que a área com maior incidência, Tancredo Neves, pertence a esta região. A RISP Atlântico possui os melhores indicadores em todos os meses, ou seja, possui a menor média de ocorrências e, portanto, poderia ser considerada a região mais segura. Através da média, conseguimos extrair indicadores capazes de fazer comparações diretas entre as regiões! Isso é importante para avaliar situações de forma mais abrangente em um cenário mais amplo para a cidade de Salvador. Para deixar ainda mais claro o cálculo desta medida, a Figura 5.9 apresenta as etapas para calculá-la através do estudo de caso. Figura 5.9: Etapas para calcular a média A Figura 5.9 mostra o passo a passo simples para calcular a média de ocorrências para uma das regiões de Salvador em janeiro. Note que ao final a média apresentou um resultado aproximado, diferente da Tabela 5.2 que apresentou alguns valores decimais, mas qual seria o motivo? Bom, estamos tratando de números de ocorrências, certo? Você nunca ouviu algo como “Ontem acontecem 2,5 assaltos naquele ponto de ônibus” ou “Aconteceu em Salvador 30,5 furtos de veículos na região do litoral” e mesmo assim o valor da média é decimal na Tabela 5.2. Isto ocorre, pois estamos tratando de uma variável que por natureza é inteira, ou seja, aumenta em unidades, porém a forma como a média é calculada não é garante que o resultado seja também um inteiro (algumas vezes pode acontecer). Logo, é comum realizar uma aproximação simples seguindo as regras: Caso a parte decimal seja maior ou igual 0,5, você aproxima para o maior valor inteiro próximo do seu número Caso a parte decimal seja menor que 0,5, você aproxima para o menor valor inteiro próximo do seu número Esta regra vale para qualquer valor decimal que você queira representar e não somente a média. Aplicando esta regra na Tabela 5.2, assim como foi aplicada na Figura 5.9, temos: Tabela 5.3: Médias encontradas após aproximação para as ocorrências de assalto à ônibus separada por região RISP Janeiro Fevereiro Março Atlântico 9 6 7 BTS 12 9 12 Central 19 13 16 A Tabela 5.3 mostra de forma a média com a mesma natureza da grandeza estudada, ou seja, em valores inteiros mantendo o seu conceito: representar um ponto de equilíbrio para o número de ocorrências de assaltos a ônibus por região em Salvador. Com os valores das médias calculados por região, podemos assinalar outro situação, protagonizada pela novamente pela área Tancredo Neves na região Central… Você conseguiu perceber? Olhe para as médias da região Central: 19 ocorrências em Janeiro, 13 ocorrências em Fevereiro e 16 ocorrências em Março. Agora olhe novamente para esta mesma região na Figura 5.8 e responda: estes valores de média fazem sentido? Infelizmente não. A situação que ocorre aqui mostra uma das fraquezas desta medida: valores aberrantes. Tratam-se de observações demasiadamente grandes ou pequenos que apresentam um grande afastamento das demais. Neste caso a responsável por esses valores é o setor Tancredo Neves, com números de ocorrências muito maiores em comparação aos demais. Os valores aberrantes influenciam bastante na média e isso será discutido mais a frente … Agora que aprendemos como calcular e utilizar a média, podemos compreender a frase dita no início desta seção: “Em média ocorreram 3 assaltos em Salvador por dia avaliados durante o ano” Basicamente o que o jornal apresentou foi um tratamento similiar ao que fizemos anteriormente: Adquiriu todos os os boletins mensais disponibilizados pela SSP, somou todos os números de ocorrências de Janeiro até Dezembro e então dividiu pelo total de dias que existem no ano, 365 dias. É provável que o valor encontrado tenha sido decimal também, e então foi aproximado para este valor que verificamos: três ocorrências em média! Podemos aplicar esta mesma análise para o nosso banco de dados. Considerando os dias vigentes de cada mês no ano de 2019, podemos dizer que: Em Janeiro ocorreram em média 6 assaltos à ônibus por dia em Salvador. Em fevereiro ocorreram em média 5 assaltos à ônibus por dia em Salvador. Em março ocorreram em média 5 assaltos à ônibus por dia em Salvador. Note que esses valores foram encontrados considerando a aproximação discutida anteriormente. Além disso, com a tabela calculada podemos dizer frases como: “Durante o período de Janeiro, em média ocorreram doze assaltos à ônibus” “Em Fevereiro, na Região BTS, aconteceram nove assaltos à ônibus em média” Depois de compreender um pouco sobre a medida mais usada e saber uma de suas falhas (valores aberrantes), será que existe alguma outra medida que seja blindada a esta questão? Para nossa sorte, ela existe e se chama Mediana. A mediana é definida como o valor que divide os dados na metade, 50% estão acima da mediana e 50% estão abaixo. A obtenção da mediana é feita ordenando-se os dados e escolhendo-se o valor do meio. Por exemplo se temos 11 valores, a mediana estará na 6º posição (5 valores abaixo e 5 valores acima). No caso de uma quantidade amostral par, computamos a média dos dois valores “centrais”. Tabela 5.4: Medianas encontradas para as ocorrências de assalto à ônibus separada por região RISP Janeiro Fevereiro Março Atlântico 7,0 6,0 6,0 BTS 10,5 9,5 11,5 Central 11,0 9,0 9,0 A Tabela 5.4 apresenta os valores das medianas para cada região de Salvador. Note que algumas regiões apresentam valores decimais, assim como aconteceu com a média e o motivo é o mesmo: ao calcular a média dos valores “centrais” não garantimos um resultado inteiro. Para compreender melhor este resultado, na Figura 5.10 apresentamos o passo a passo para calcular esta medida. Figura 5.10: Etapas para calcular a mediana Na Figura 5.10 mostramos em duas regiões diferentes de Salvador como calcular a mediana. Note que ela pode ser encontrada de duas maneiras distintas a depender da quantidade de valores como apresentamos anteriormente. Figura 5.11: Gráfico de pontos para as ocorrências em Salvador Na Figura 5.11 avaliamos essas duas medidas junto a grandeza estudada através de uma nova visualização: gráfico de pontos. Podemos perceber na Figura 5.11 que para as regiões Atlâtico e BTS os valores de média e mediana são próximos, diferente da região Central. Essa disparidade é explicada pelo que vimos anteriormente: O valor aberrante distorce o valor da média, puxando-a em sua direção como vocês percebem. A comparação de média e mediana pode ser um bom indicativo para verificar a presença de um valor aberrante: quanto mais próximos essas medidas forem, mais provável a ausência de valores aberrantes. Nesta análise em específico, verificamos que a mediana seria uma melhor medida para representar a região Central como um todo, já para as outras duas regiões a escolha entre ambas as medidas é arbitrária, pois elas estão bem próximas. São visualizações como essas que ajudam o cientista de dados a tomar melhores decisões na escolha de indicadores ou medidas de resumo. Logo, conseguimos perceber que no geral a região mais perigosa, ou melhor, a área mais perigosa durante o verão de 2019 foi Tancredo Neves. Finalmente, a última medida de tendência central a ser mencionada neste capítulo é a moda. Trata-se da medida de maior frequência em um conjunto de dados, em outras palavras, o valor que mais se repete em uma amostra será a moda deste dado. Este conceito é muito usado com variáveis categóricas. Como neste capítulo trabalhamos com valores numéricos, não cabe sua análise deste medida. 5.3 Medidas de dispersão Como já foi visto as medidas de posição ou se preferir, tendência central, podem ser utilizadas para descrever as informações através de um único valor. Porém e se dois conjuntos possuirem o mesmo valor de média ou mediana, podemos dizer que eles são equivalentes? A resposta é Não! Apesar destas medidas resumirem bem os conjuntos de informações, perdemos outras características importantes. Para alcançar uma visão geral e expandir nossas análises usamos também as medidas de dispersão2. Figura 5.12: Explicação das medidas de dispersão Para entender melhor este conceito e a necessidade de saber entender melhor essas medidas dispersão avalie a Figura 5.12 onde apresentamos duas situações: Na “Situação 1” podemos perceber que os dados apresentam um espalhamento ou dispersão em relação a medida de posição, lembre que o triângulo busca resumir todas as bolinhas. Isto significa dizer que há variação entre os valores observados em comparação a uma medida qualquer de posição, o que torna este conjunto heterogêneo, ou seja, bem diversificado. Já na “Situação 2” vemos uma situação oposta, onde a massa de dados está bem localizada ao redor da medida de posição inclusive bastante próxima, mostrando assim um conjunto de dados homogêneo. Quanto mais homogêneo for um conjunto em relação a uma medida de posição, maior será o poder de explicação desta medida sobre o conjunto. Portanto, medidas de dispersão são medidas capazes de relacionar o afastamento dos dados em comparação à uma medida de posição, que estudamos na seção anterior. Existem várias formas de se medir, porém será tratado como tópico de discussão a Amplitude, Desvio padrão e Distância Interquartil. Essas medidas se tratam de um complemento, pois agora conseguimos entender como os dados estão espalhados em relação a medida central calculada. A primeira medida a ser trabalha é a amplitude definida como: \\[Amplitude=Valor\\ Máximo\\ -\\ Valor\\ Minímo\\] Seu conceito é bastante simples de entender. Figura 5.13: Gráfico de pontos para as ocorrências em Salvador Na Figura 5.13 apresentamos novamente o gráfico de pontos da seção anterior para o número de ocorrências. Podemos perceber de forma visual, que a amplitude da região Central será maior do que todas as outras regiões em todos os meses, pois a área de Tancredo Neves apresenta grandes índices de assaltos, como foi discutido anteriormente. Em geral, a amplitude apenas permite comparar dois ou mais conjuntos no sentido de avaliar quem apresentar a maior ou menor variação em relação a outra, porém não dá resposta em relação à distribuição dos dados e como eles estão espalhados em torno de uma medida de posição. Além disso, assim como a média essa medida sofre bastante com a presença de valores aberrantes, a amplitude também sofre … Você consegue identificar o motivo? Agora que entendemos um conceito mais simples, vamos partir para a compreensão de dois conceitos um pouco mais complexos: Desvio padrão e Distância Interquartil. O Desvio Padrão relaciona a diferença entre cada elemento do conjunto com a média aritmética através de uma fórmula matemática. Ou seja, cada elemento terá um determinado valor de variação em relação à média do grupo e desta forma, é possível saber quando os conjuntos analisados são heterogêneos ou homogêneos. Isso confirma que esta medida consegue representar a dispersão dos dados, já que utiliza todos os valores do conjunto no seu cálculo. Sua fórmula não será apresentada neste material, pois foge do escopo do livro. Na ciência, esta medida junto com a média é essencial para construir análises e resultados, pois esta dupla se complementa, sendo as mais utilizadas. A Distância Interquartil, diferente da amplitude, é mais robusta à valores aberrantes. Para entender a distância interquartil precisamos inicialmente definir os quartis. Quartis são valores que dividem os dados em quatro partes e eles são: \\(Q1\\) (primeiro quartil) define o valor para o qual 25% dos valores estão abaixo dele; \\(Q2\\) (segundo quartil) é o valor que tem 50% dos valores abaixo e 50% acima; \\(Q3\\) (terceiro quartil) define o valor que possui 75% dos dados abaixo dele. Onde, a fórmula para a distância interquartil será a diferença entre o primeiro e terceiro quartil: \\[Distância\\ Interquartil\\ =Q3-Q1\\] Note que o \\(Q2\\) é um conhecido nosso: a mediana. Logo, dá para perceber que para calcular essa medida precisamos fazer o mesmo método que utilizamos: ordenar os dados e extrair os quartis. Para facilitar o cálculo desta medida, podemos utilizar o seguinte procedimento: Ordenar os dados de forma crescente Seja \\(N\\) a quantidade de valores do seu conjunto, podemos calcular as posições dos quartis \\(Q3\\) e \\(Q1\\) da seguinte forma: \\[Posição\\ de\\ Q1=N*0,25\\] \\[Posição\\ de\\ Q3=N*0,75\\] Verificar se as posições encontradas são valores inteiros ou decimais. Se for decimal, aproximar para o valor inteiro mais próximo seguindo a regra ensinada na seção anterior. Encontrar os quartis \\(Q1\\) e \\(Q3\\) da seguinte forma: calculando a média entre o valor na posição encontrada com o valor seguinte na sequência. Finalmente, com os quartis em mãos, calcule a distância entre o terceiro e o primeiro para encontrar a Distância Interquartil. Na Figura 5.14 apresentamos os passos explicados anteriormente de forma prática em nosso estudo de caso. Figura 5.14: Etapas para calcular Distância Interquartil A Figura 5.14 detalha os passos apresentados para o cálculo da distância interquartil na RISP Atlântico no mês de Janeiro, mostrando que apesar de parecer complexo as etapas são bem simples de resolver! Porém, o mais comum no dia a dia de um cientista de dados é utilizar o computador através de programas e códigos para encontrar esses resultados. Para entender melhor as medidas de dispersão, vamos calculá-las para o nosso caso de estudo: número de ocorrências de assalto à ônibus em Salvador. A Figura 5.15 resume os resultados encontrados dessas medidas para cada região de Salvador separado por mês. Figura 5.15: Medidas de dispersão aproximadas em gráfico de barras das ocorrências de Salvador Conseguimos extrair as seguintes informações: Considerando a amplitude, vemos que a região central é que mais varia em todos os meses em comparação com BTS e Atlântico. Isso indica uma grande disparidade entre o máximo de ocorrências, Tancredo Neves, com as demais. Esta região impacta inclusive no resultado do Desvio Padrão que é o dobro em comparação as demais regiões. O menor Desvio Padrão avaliado está no mês de fevereiro para a RISP Atlântico. O valor 4 pode ser lido da seguinte forma “No mês de fevereiro a diferença entre o número de ocorrências por área com a média da região é de quatro ocorrências” No geral, o conjunto com maior espalhamento é representado pela RISP Central, que demonstrou os maiores valores em todas medidas. Essa tendência é observada também na Figura 5.13 onde as outras regiões mostram número de ocorrências similares. Um fato a ser ressaltado sobre a Distância Interquartil: Apesar de ser uma medida robusta a valores aberrantes, assim como a mediana, ao avalia-la com um conjunto muito pequeno, como é o caso da RISP Central, essa robustez acaba se tornando fraca. Outro ponto a ser ressaltado é que amplitude e desvio padrão possuem uma relação: quanto mais próximos os dados estiverem do valor médio, significa que há uma amplitude menor e consequentemente um desvio padrão dos dados também será pequeno, por outro lado quando os dados se afastam do valor da média, é indicado que a amplitude é maior e consequentemente, o desvio padrão também será maior. No geral utilizar mais de uma medida descritiva é essencial para se atingir uma boa conclusão a respeito dos dados que estão sendo avaliados. Além disso, o diagnóstico encontrado ao se utilizar uma medida é confirmado pelas outras. Por isso a importância de conhecer as medidas de Tendência Central e Dispersão para interpretar nossos dados e garantir conclusões confiáveis! Na próxima seção iremos expandir ainda mais o que aprendemos aqui, trazendo conclusões mais factíveis ao nosso caso de estudo através do Diagrama de caixas. 5.4 Diagramas de Caixa Nesta seção vamos tratar sobre o Diagrama de Caixa (chamado comumente de boxplot), uma das visualizações mais completa de dados numéricos que um cientista de dados possui e que resume as duas ideias apresentadas anteriormente: tendência central e dispersão. Antes de mergulhar em sua utilização através do nosso caso de estudos, vamos explicar o que é cada parte dessa “caixinha”. Figura 5.16: Diagrama de caixa explicado para o mês de Janeiro Na Figura 5.16 apresentamos de forma elegante nosso diagrama de blocos referente ao mês de janeiro. No geral, quando olhamos este tipo de visualização focamos em 4 elementos principais2: Mediana: Trata-se da medida de blindada a valores aberrantes e que separa o conjunto de dados em 50% para cada lado como aprendemos anteriormente. Distância Interquartil: Nossa medida de dispersão definida anteriormente. Assim como a mediana, trata-se de uma medida blindada a valores aberrantes. Limites: São valores calculados a partir da distância interquartil e de seus elementos. Responsáveis por definir “a última fronteira” entre valores comuns e aberrantes. São separados em dois como vimos na Figura 5.16: Limite Superior e Limite Inferior. O Limite Superior é calculado: \\[Limite\\ Superior=Q3+1,5*Distância\\ Interquartil\\] Já o Limite Inferior é calculado como: \\[Limite\\ Inferior=Q1-1,5*Distância\\ Interquartil\\] Valor Aberrante: Todo valor que ultrapassa a barreira definida pelos limites. Na maioria das vezes são definidos como pontinhos. Considerando esses elementos discutidos, percebemos que: a linha superior da nossa caixa retrata o \\(Q3\\), já a linha inferior o \\(Q1\\), pois \\(Q3-Q1=Distância\\ Interquartil\\) como vemos na Figura 5.16. Finalmente, a linha do meio, que divide a caixa em duas, é a nossa \\(Mediana\\). Não é garantido a existência de valores aberrantes como na Figura 5.16. Eles só ocorrem se ultrapassar o limite superior ou inferior. Apesar de usarmos mediana e distância interquartil, poderíamos ter utilizado a média junto com o desvio padrão, porém o mais comum é utilizar os dois primeiros. Neste momento você pode se perguntar: “Mais o que este gráfico pode me oferecer? Qual o sentido de eu aprender seus elementos?” E a resposta é simples: Ele condensa muitas informações de forma robusta e de fácil percepção! O diagrama de caixas nos fornece: dispersão dos dados (distância interquartil) em torno de uma medida de posição (mediana), presença de valores aberrantes e assimetria dos dados. Vamos discuti-las através do nosso caso de estudo através da construção de diagramas de caixa para cada mês do verão em 2019. Figura 5.17: Diagrama de caixa das ocorrências mensais Através da Figura 5.17 avaliamos as ocorrências de assaltos à ônibus em Salvador dividos pelos meses do verão. Note que não estamos trabalhando mais com AISP ou RISP e sim com a cidade de Salvador, ou seja, reduzimos aquela tabela inicial em três caixinhas! Primeiramente, antes de entrar em uma análise mais aprofudanda desta Figura, vamos responder em tópicos a seguinte pergunta: Qual seria o melhor diagrama de caixas para o número de ocorrências de assalto ônibus em Salvador para um determinado mês? Com o que aprendemos até então neste capítulo, poderiamos dizer: Um baixo valor de mediana, pois assim teríamos uma baixa incidência de assaltos. Sem valores aberrantes. Caso exista incidência de valores aberrantes acima da caixa, estaremos enfrentando casos extremos certo? afinal eles estariam muito acima das outras áreas. Já valores aberrantes abaixo da caixa pode demonstrar que apenas poucas regiões são seguras na cidade em comparação aos demais. Esses dois tópicos resumem bem o que um policial ou delegado gostaria de ver em relação a sua cidade: um baixo número de ocorrências. Vamos agora avaliar de forma aprofundada o que conseguimos verificar nesses três meses de 2019: Se considerarmos a mediana, podemos verificar que Janeiro apresentou o maior valor, logo um cenário ruim em comparação aos demais. Em outras palavras, podemos dizer que foi o mês com maior incidência central. Considerando a distância interquartil, ou se preferir a altura da caixa, verificamos que o mês de janeiro apresentou a maior variação em torno da mediana, valor que separa o conjunto em duas partes de 50%. Mas … O que significa dizer isso? Significa dizer que tivemos áreas com muitos assaltos e outras com poucos assaltos. Lembre-se que dentro da caixa representamos 50% das nossas áreas! Considerando o mês de janeiro por exemplo, vemos que o limite inferior é equivalente à 5 ocorrências de assalto enquanto o limite superior está entre 15 e 20 ocorrências, mais de três vezes o valor inferior! Demonstrando um desbalancaeamento entre áreas neste mês e uma assimetria na ocorrência de casos. Conseguem ver aqueles potinhos em cima de cada caixa? Eles são nossos valores aberrantes e são de uma área bastante citada neste capítulo: AISP Tancredo Neves. Os valores de ocorrência foram tão altos nessa região, durante todos os meses, que o diagrama de caixa os coloca como valores aberrantes. De forma geral, conseguimos verificar que janeiro foi o mês com maiores ocorrências por região apresentando os maiores: Limite superior, Q3 e Mediana, ou seja, podemos dizer que foi o pior mês do verão de 2019 para se andar de ônibus. Já fevereiro pode ser considerado o melhor:sua caixa se concentra em uma região de 3 à 10 ocorrências com um limite superior máximo de 15 ocorrências. Além disso, apresentou a menor ocorrência do nosso pior setor Tancredo Neves com 25 ocorrências. Finalmente, março ocorreu uma piora em comparação a fevereiro através da deslocação da caixa para uma região de 5 à 12 assaltos, porém não superou janeiro. Através desta simples visualização, conseguimos extrair muitas respostas a cerca do nosso caso de estudo, inclusive muitas de comparação! 5.5 Concluindo … Através deste capítulo conseguimos entender que através de alguns indicadores conseguimos analisar e discutir grandes tabelas. Além disso, avaliamos uma nova forma de visualizar nossas informações: o diagrama de caixa. Por meio do infográfico da 5.18 resumimos o verão de 2019 de Salvador em relação aos assaltos à ônibus na cidade. Figura 5.18: Conclusões sobre o tema do nosso capítulo Podemos perceber que através de uma análise descritiva simples, conseguimos chegar em diversas conclusões a respeito do tema estudado. Estas conclusões podem embasar políticas públicas para melhorar esses indicadores. Além disso, aprendemos que: Apesar de existirem diferentes tipos de medidas para apresentar um mesmo conceito, elas se diferem em quando utilizá-las. O diagrama de caixa é uma ótima ferramenta para ter uma visão geral a respeito do nosso conjunto de dados. Dominar essas ferramentas é uma peça fundamental para o cientista de dados exercer seu trabalho e responder questões. 5.6 Indo Além Agora que já aprendemos um pouco sobre Estatística Descritiva que tal aplica-lo na prática? Você agora é cientista contratado pelo governo de Salvador para compreender e descrever melhor as ocorrências de roubo de veículos na capital baiana durante o mês de Dezembro. A Figura 5.19 mostra o boletim da SSP que lhe foi enviado (no formato .csv), constando as ocorrências de todos os delitos na capital baiana no mês de dezembro1. Figura 5.19: Boletim de dezembro de 2019 produzido pela SSP O gestor pediu que apresentasse, em relação ao delito de roubo de veículos: Qual a RISP que precisa ser mais monitorada pelos profissionais? Em média, quantos roubos estão acontecendo por região? Qual a região com menor incidência de casos? Consegue descrever uma motivação para isso. Descrição completa deste delito através de uma visualização gráfica. Então, com o conhecimento que desenvolvemos até aqui, resolva essas questões usando programação! 5.7 Citações no capítulo [1] Secretaria de Segurança Pública. Boletins mensais de delitos. Disponível em: link de acesso [2] Sergio Miranda Freire. Bioestatística Básica, Capítulo 3 – Medidas de Tendência Central e Dispersão Disponível em: link de acesso "],
["cap6.html", "Capítulo 6 Coletando Dados para Pesquisas 6.1 Como é realizado a coleta de dados 6.2 Amostragem 6.3 Viés Amostral 6.4 Ética na Construção de Bancos de Dados 6.5 Você Sabia? Pesquisa Eleitoral 6.6 Referências", " Capítulo 6 Coletando Dados para Pesquisas 6.1 Como é realizado a coleta de dados 6.2 Amostragem 6.3 Viés Amostral 6.4 Ética na Construção de Bancos de Dados 6.5 Você Sabia? Pesquisa Eleitoral 6.6 Referências "],
["cap7.html", "Capítulo 7 Distribuições, Probabilidade e Possibilidade", " Capítulo 7 Distribuições, Probabilidade e Possibilidade "],
["cap8.html", "Capítulo 8 Entendendo e Avaliando sua Hipóteses 8.1 O que é “Teste de Hipóteses”? 8.2 Hipóteses estatísticas 8.3 p-valor 8.4 Verificando a normalidade 8.5 Uma breve contextualização! 8.6 Concluindo… 8.7 Indo além Referências", " Capítulo 8 Entendendo e Avaliando sua Hipóteses Olá, neste capítulo iremos aprender sobre o Teste de Hipóteses.Ele é mais uma das ferramentas estatísticas que nos permite tomar decisões com base nas informações que obtivemos de uma amostra! Lembre-se que: quando selecionamos uma amostra precisamos atender alguns pressupostos que foram discutidos nos capítulos 6 e 7. Se as condições de seleção estiverem adequadas, então dizemos que esta amostra representa bem a população, não é mesmo? Com isso, qualquer estatística que calcularmos sobre a amostra poderá ser generalizada para a nossa população. Uma forma de comprovar isto é fazendo o teste de Hipóteses. Mas a discussão não para por aqui. Ainda temos muita coisa interessante para aprender! Então, vamos começar? 8.1 O que é “Teste de Hipóteses”? Vamos utilizar um exemplo sobre pesquisas eleitorais. Observe as manchetes na Figura 8.1 e tente compreendê-las. Figura 8.1: Pesquisas de intenção de voto Vemos que estas pesquisas utilizam a estatística para apontar os possíveis “vencedores” para prefeito de Salvador e governador do Estado da Bahia. Mas, devemos nos lembrar que estas pesquisas não foram realizadas com TODOS os eleitores, ou seja, não foi realizada com toda a população de eleitores destas localidades. Isto porquê, como visto no cap 7, uma entrevista com toda a população de interesse demandaria muito tempo e recursos financeiros para deslocamento, contratações, entre outros fatores. Por isso, utiliza-se amostras, uma parcela de indivíduos capaz de representar bem a população. Por conta disso, precisamos fazer algumas suposições ou hipóteses para verificar se é possível que a população tenha um determinado valor para o parâmetro que investigamos a partir da amostra selcionada. Veja que legal, o teste de hipóteses garante que mesmo não tendo utilizado toda a população, encontramos resultados confiáveis que podem ser extrapolados como parâmetros populacionais. Observe a Figura 8.2, ilustrando este conceito. Figura 8.2: Porquê fazer teste de hipótese? O processo de Inferência está sujeito a erro. Sim, devido ao fato de estarmos utilizando uma amostra para generalizar resultados para uma população. Este erro nunca será zero, a menos que não trabalhemos com amostra, e sim diretamente com a população, como é feito com as pesquisas do CENSO. 8.2 Hipóteses estatísticas As Hipóteses Estatísticas são suposições feitas sobre o valor de um parâmetro populacional, ou a natureza de uma distribuição da população. 1 - A temperatura corporal média de adultos é 37°C? 2 - A taxa de natalidade de Salvador mudou nos últimos 5 anos? 3 - A proporção de mulheres com depressão é 5% 4 - A carga horária média de trabalho de funcionários de uma empresa é 40 horas semanais Observe que as suposições dos exemplos ocorrem sobre uma população de interesse. Para verificar estas suposições precisamos fazer cálculos, que consideram as estatísticas da nossa amostra. Portanto, de acordo com os resultados destes cálculos, a nossa hipótese estatística pode ser aceita ou rejeitada. Podemos então pensar uma hipótese para o caso da Figura 8.1, com a intenção de votos do candidato Rui Costa. Imagine que a pesquisa ainda não tenha sido feita, portanto ainda não temos o resultado. Inicialmente, o candidato estava afirmando que teria 70% dos votos. Nossa primeira suposição para investigar seria: 1 - A proporção de votos para o candidato Rui Costa é 70% O teste de hipóteses é composto por duas afirmativas. A primeira, que já elaboramos, é conhecida por hipótese nula. E a segunda hipótese, complementar, é conhecida como hipótese alternativa. A hipótese nula é uma afirmativa de que parâmetro populacional é igual a um determinado valor. Já a hipótese alternativa é uma afirmativa de que o parâmetro tem um valor que difere da hipótese nula. Mas, o que é o parâmetro populacional? No caso deste exemplo, nosso parâmetro populacional é a intenção de votos para o candidato Rui Costa. Convencionalmente, utilizamos símblos para identificar estas hipóteses: Figura 8.3: Porquê fazer teste de hipótese? Assim, podemos afirmar como hipótese alternativa: 2 - A proporção de votos para o candidato Rui Costa é menor do que 70% Em termos matemáticos, podemos escrever da seguinte forma: H0: A proporção de votos para o candidato Rui Costa é = a 70% H1:A proporção de votos para o candidato Rui Costa é menor que 70% Observe que as hipóteses são complementares, isto implica que o que é afirmado em uma hipótese não deve ser afirmado em outra. Agora, suponha que tenham dado início à pesquisa eleitoral. Uma equipe de profissionais selecionou uma amostra de forma adequada e atingiram a estimativa de intenção de votos para Rui Costa igual a 61%. Após o teste de hipótese, podem inferir este valor como parâmetro populacional, como foi divulgado na reportagem da Figura 8.1. Qual hipótese está correta, H0 ou H1? Em um teste de hipóteses temos duas opções: 1 - Rejeitar H0: neste caso confirmamos que a proporção de votos não equivale a 70% 2- Não rejeitamos H0: neste caso confirmamos que a proporção de votos é igual a 70%. No nosso exemplo, devemos rejeitar a hipótese nula H0, já que a intenção de votos no candidato é 61%. Neste caso, atribuímos o &lt; (menor que) para a nossa hipótese alternativa, mas poderíamos optar por colocar os símbolos &gt;(maior que) ou o diferente. Figura 8.4: Porquê fazer teste de hipótese? 8.3 p-valor O P-valor também é conhecido como nível descritivo, e representa uma probabilidade em se obter estimativas iguais ou mais extremas, supondo que a hipótese nula seja verdadeira. Eu sei que parece complicado, de fato é! Mas vamos destrinchar cada parte desta afirmação e você verá que é possível entendê-la. Para isto, vamos voltar ao exemplo da intenção de votos, cujas hipótestes eram: H0: A proporção de votos para o candidato Rui Costa é = a 63% H1:A proporção de votos para o candidato Rui Costa é menor que 63% Supomos que a intenção de votos para Rui Costa é 65%, lembre-se que esta afirmação é sobre a população de interesse, ou seja, todos os eleitores baianos que tem voto válido. Bom, como já discutimos, é inviável entrevistar cada eleitor, por isso selecionamos uma amostra representativa.Então, acreditamos que a proporção populacional é 63%, mas como estamos fazendo uma amostragem esperamos que nosso resultado final tenha alguma variação em relação aos 63% (lembra quando citamos o erro estatístico?). Também já sabemos que após as entrevistas, foi visto que 61% planejava votar no candidato Rui Costa. O valor de 61% claramente é menor/ diferente dos 63% que estamos supondo no teste. A primeira coisa que passa pela mente é rejeitar logo a nossa hipótese nula, não é mesmo? Claro, olha a diferença entre 63% e 61%. Aqui é o grande ponto:será que esta diferença é de fato estatisticamente significativa ou será um mero acaso? Podemos fazer esta pergunta de forma um pouco mais estatística: se pegassemos outras amostras para realizar a análise, qual a probabilidade do valor 61% ocorrer? Esta pergunta é importante porque se esta probabilidade for alta, significa que nossa hipótese nula H0 deve ser rejeitada. Mas, se esta probabilidade for mínima, quer dizer que o valor de 61% ocorreu devido ao acaso e, nossa hipótese nula H0 não deve ser rejeitada. Esta probabilidade é conhecida como p-valor, ou nível descritivo. Quando utilizamos expressões como estatisticamente significativa ou significância estatística, estamos na realidade querendo saber a que condições a nossa suposição deve ser aceita ou rejeitada. Se você chegou até aqui, parabéns! Já entendeu metade da afirmação inicial: “P-valor também é conhecido como nível descritivo, e representa uma probabilidade em se obter estimativas iguais ou mais extremas” Vamos continuar a discussão… A segunda parte da afirmação diz: “supondo que a hipótese nula seja verdadeira.” Isto significa que sempre vamos partir da crença de que nossa H0 é realmente verdadeira. Caso contrário, não faria sentido testá-la, automaticamente já aceitaríamos a hipótese alternativa. Suponha agora, que os dados das entrevistas de intenção de votos já tenham sido coletados e, foram enviados para as análises estatísticas. Temos um interesse específico sobre quantos entrevistados afirmaram votar em Rui Costa, lembra?! Atenção, até este momento ainda não confirmamos nada sobre a nossa hipótese. Toda esta discussão está nos direcionando ao próximo passo do nosso teste que é justamente a avaliação do p-valor. Vamos observar graficamente o comportamento da nossa amostra. Figura 8.5: Histograma Este gráfico não é uma novidade para você! No Capítulo 3 @/Cap3 diversos tipos de gráficos foram apresentados, inclusive este, o Histograma. Além disso, no capítulo anterior @/Cap7 você viu a importância do histograma para identificar e avaliar o formato de distribuições estatísticas. O Histograma é uma excelente ferramenta visual para identificarmos uma Distribuição Normal. E porquê isto é importante? Porque, como visto no capítulo anterior, as hipóteses e considerações estatísticas se baseiam em um distribuição normal. A Figura 8.5 indica no eixo x, a proporção de pessoas que afirmaram votar no candidato Rui Costa tomando várias amostras aleatórias diferentes. Observe que a proporção varia de 57 a 65, sendo indicado no eixo, 58 a 64. Sabemos que o eixo y indica a frequência destas observações. O nosso valor com maior frequência de ocorrência ou, o mais provável é o valor central de 61. Isto significa, que se selecionássemos várias amostras de entrevistados, a maioria delas iria indicar a procentagem de votos para Rui Costa de 61%. Percebemos uma tendência central de ocorrência deste valor. Perceba também, que é muito pouco provável a ocorrência de 63% de votos para o candidato, uma vez que este valor apresenta uma frequência muito baixa. Mas, vamos prosseguir nossas confirmações. Lembrando, nossas hipóetses são: H0: A proporção de votos para o candidato Rui Costa é = a 63% H1:A proporção de votos para o candidato Rui Costa é menor que 63% Assim, a Figura abaixo mostra a probabilidade, o p-valor da ocorrência da nossa hipótese nula. Figura 8.6: p-valor da hipótese nula Então, testando a nossa H0, é como dizer: “quão provável é que as intenções de voto para Rui Costa sejam 63%?” O teste de hipótese acontece por meio do cálculo de um parâmetro estatístico de teste, vinculado ao p-valor deste teste. O p-valor obtido foi 2.2 x 10-16 (0,0000000000000022). Este valor pode ser considerado 0. Por este motivo, podemos rejeitar a nossa hipótese nula, o que nos leva a ter mais argumentos a favor da nossa hipótese alternativa, como indicado pela seta 2. Portanto: REJEITAMOS a hipótese nula! Mas, existe um fator muito importante que determina a nossa rejeição ou não rejeição de uma hipótese. Nós precisamos definir o nível de significância do nosso teste antes de fazer a análise. Isto porque é a partir dele que vamos saber o que podemos considerar “provável” ou não. O nível de significância é representado pela letra grega \\(\\alpha\\) (alpha). Então, quando decidimos a qual nível de significância estamos trabalhando, teremos uma noção de quão pequeno o p-valor deve ser, para termos resultados estatisticamente significativos. Na prática, o alfa é um ponto de corte para a rejeição da hipótese nula. Podemos traduzir toda essa explicação em: Se o p-valor menor ou igual a \\(\\alpha\\): rejeitamos a hipótese nula em favor da alternativa. Se o p-valor maior que \\(\\alpha\\): não rejeitamos a hipótese nula. No caso da nossa pesquisa, estamos trabalhando com \\(\\alpha\\) = 5%, que implica em um Intervalo de Confiança de 95%. Mas poderiam ser utilizados outros valores, como 90%, 98% ou 99%. Então, finalizamos o nosso teste de hipóteses para a intenção de votos no candidato Rui Costa. Poderíamos fazer o seguinte enunciado: O candidato Rui Costa afirmou que teria 63% de intenção de votos na disputa eleitoral. Queremos verificar se esta informação é verídica, utilizando dados da pesquisa de intenção de votos realizada posteriormente. Portanto, queremos testar se a intenção de votos para o candidato Rui Costa é 63% à um nível de significância(\\(\\alpha\\)) 5%. H0: A proporção de votos para o candidato Rui Costa é = a 63% H1:A proporção de votos para o candidato Rui Costa é menor que 63% Assim, nossa resposta a este etste pdoeria ser: A um nível de significância (\\(\\alpha\\)) de 5% nosso resulatdo é estatisticamente significativo (p- valor 2.2 x 10-16). Concluímos que a intenção de votos para o candidato Rui Costa não será igual a 63%. Segundo o p-valor obtido no teste, rejeitamos a hipótese nula. E Por que não dizer que aceitamos a hipótese alternativa? Bom, basicamente, a nossa motivação e análise do teste foi feita para H0, lembra? Por isso, nossa conclusão também deve ser relacionada a esta hipótese. E com isso, vimos que a afirmação do candidato estava equivocada e, como foi comprovado e divulgado depois, a intenção de votos para ele é 61%, um valor menor do que testado. 8.4 Verificando a normalidade Você já sabe a importância da normalidade, mas já parou pra pensar que precisamos garantir que estamos trabalhando sobre a hipótese da normalidade? Para isto, podemos utilizar ferramentas como a interpretação gráfica ou podemos testar estatisticamente os dados para verificar se a distribuição é de fato normal. 8.4.1 Gráficos de normalidade: Histograma e Q-Q Plot Bom, no exemplo da pesquisa eleitoral você já viu o Histograma. Pois bem, ele é a primeira ferramenta que pode ser aplicada para verificar a normalidade da distribuição de variáveis. Neste sentido, observamos que a curva apresnetada tende a se assemelhar com o formato de um sino, onde há um valor central que ocorre mais vezes, assim como vimos na Figura 8.5 cujo valor central é 0.61. Uma outra forma gráfica bastante utilizada é o Q-Q Plot. Observe a Figura 8.7, o qq-plot dos dados do nosso exemplo. No eixo y indicam-se os valores reais e no eixo x indica-se os valores teóricos. Isto significa que ao fazer um qqplot de qualquer conjunto de dados, estamos comparando os valores reais com os valores teóricos ou seja, valores que ocorreriam caso a distribuição dos dados fosse normal. Se os pontos estiverem próximos à reta indicada, significa que a distribuição é normal. Figura 8.7: q-q plot de distribuição normal Mas, e quando temos outras distribuições? Naturalmente, o perfil visual verificado nestes gráficos será diferente. Veja por exemplo um histograma de uma distribuição exponencial. Observe a diferença de formato. Figura 8.8: Formato da distribuição Exponencial O qq-Plot destes dados fica da seguinte forma: Figura 8.9: q-q plot disrtibuição não normal Compare a Figura 8.9, com a Figura 8.7 e perceba as diferenças em como os pontos se ajustam à linha vermelha. Esta linha indica teoricamente onde os pontos deveriam estar se os dados seguissem uma distribuição normal. Por isso, na Figura 8.7 vemos uma aderência à linha, que não é vista na Figura 8.9. Apesar de ser visualmente possível detectar uma distribução normal, esta forma de análise não é a mais segura. Isto porque há muitas variações no perfil geral dos gráficos, que nos faz acreditar que uma distribuição é normal quando na realidade ela pode não ser. E sabe como comprovar de forma confiável? Através do teste de normalidade. 8.4.2 Testes de normalidade Os testes de normalidade são importantes porque verificam a normalidade de dados através de cálculos estatísticos. Esta opção é mais segura por não é subjetiva como a análise gráfica. Existem vários testes de normalidade que dependem do tipo de dados considerados e tamanho da amostra. Shapiro Wilk, Kolmorogov-Smirnov, Anderson-Darling, são alguns dos testes de normalidade utilizados. E sim, o tamanho da amostra impacta no resultado do teste. Em geral, quanto maior a amostra, mais esperamos que a distribuição siga um perfil normal, como explicado no capítulo anterior. Os testes de normalidade são definidos a partir de hipóteses. Na realidade, são testes de hipóteses sobre a normalidade da população de onde aquela amostra foi retirada. Assim, vamos fazer duas aplicações do teste de normalidade de Shapiro Wilk para \\(\\alpha\\) = 5%, cujas hipóteses são: H0: a amostra vem de uma população normal H1: a amostra não vem de uma população normal Vamos inciar fazendo o teste para para um conjunto de dados qualquer, indicado na Figura 8.10. Figura 8.10: Dados fictícios Este teste nos fornece como resultado o parâmetro do teste, indicado por W = 0.81389, e o p-valor do teste é 2.727e-9. Lembre-se das nossas condições para o p-valor: se ele for menor que o nível de significância, temos evidências para rejeitar a hipótese nula! Portanto, o nosso p-valor que é praticamente 0 é menor do que 0,05, o que nos leva a rejeitar a hipótese nula H0 do nosso teste, trazendo evidências à favor do argumento de que nossa amostra não provém de uma população normal. E para o caso da pesquisa de intenção de votos? Bom, neste caso, vamos testar a normalidade para \\(\\alpha\\) = 5%, as hipóteses são as mesmas: H0: a amostra vem de uma população normal H1: a amostra não vem de uma população normal O resultado obtido do parâmetro do teste foi de: W = 0.99895, com p-valor = 0.8448.Como vemos, o nosso p-valor é maior que o nível de significância 0.05, portanto não rejeitamos a hipótese nula! Ou seja, nossa amostra realmente provém de uma população normal. 8.5 Uma breve contextualização! Após esta longa explicação, é possível que você ainda se pergunte de que forma todos estes conceitos são utilizados. Por isso, este tópico traz uma breve discussão sobre como os artifícios estatísticos são aplicados em conjunto para direcionar a tomada de decisão. Ainda sobre uma pesquisa eleitoral, ao verificar a Figura 8.11, vemos que abaixo dos títulos tem algumas outras informações relevantes, Margem de erro e Nível de Confiança. Figura 8.11: Dados fictícios Vamos entender primeiro o que é a margem de erro. Como o próprio nome diz, este valor mede quão exato é o resultado de uma pesquisa. No capítulo 6, você aprendeu o processo de coleta de dados para pesquisas e viu que ele está sujeito a erros, lembra? Pois bem, você também deve se lembrar que trabalhamos com uma amostra porque não conseguimos abranger toda a população de interesse. Por isso, a margem de erro indica a estimativa máxima de erro da pesquisa. Se ela aumenta a nossa confiança na pesquisa acaba sendo reduzida. Para reduzir a margem de erro, uma alternativa é aumentar o tamanho da amostra, de forma que os resultados fiquem mais confiáveis. Veja na Figura o exemplo do prefeito de Camaçari, que liderava as pesquisas com 47% das intenções de voto, com margem de erro de 4 pontos para mais ou para menos e, nível de confiança 95%. Como interpretar esta informação? Bom, se ele tem 47% das intenções de voto, mas a uma margem de erro de 4% para mais ou para menos, significa que a intenção de votos para ele pode variar de 43% até 51%! O Intervalo de Confiança (IC) indica quão provável é a pesquisa obter os mesmos resultados se for repetida diversas vezes com uma nova amostra da população. Ou seja, se entrevistássemos outros grupos de pessoas da mesma população (eleitores de Camaçari), teríamos os 47% de intenção de votos, com 4% de margem de erro? O valor 95% indica justamente isso, que em 95% das vezes o candidato estaria dentro da margem de erro. Como você já deve ter notado, o IC é um indicativo extremamente importante para análises estatísticas. Tanto que ao longo do capítulo, percebemos a importância de indicar qual o nível de confiança estamos trabalhando. Poranto, não apenas em pesquisas eleitorais, mas em qualquer investigação que você pretenda tomar uma decisão baseada em dados é preciso utilizá-lo. 8.6 Concluindo… E aí, gostou deste capítulo? Apesar de serem muitos conceitos, lembre-se que eles são essenciais para você desenvolver uma pesquisa, ou mesmo ser mais crítico ao ler notícias que divulgam resultados de pesquisas. Para te auxiliar a fixar os conteúdos discutidos, a Figura abaixo traz uma síntese dos principais aspectos tratados neste capítulo! E assim, finalizamos mais uma etapa de aprendizado, até a próxima!!! Figura 8.12: Síntese de conceitos 8.7 Indo além Foi realizada uma pesquisa para verificar a idade média dos estudantes da modalidade EJA (Educação para Jovens e Adultos) em uma escola de Salvador. Um estudo antigo apontou que a idade média da turma era de 38 anos e, atualmente, os professores tem suspeitado da presença predominante de estudantes mais jovens. Foi utilizada uma amostra aleatória de 30 elementos para a investigação. Como você definiria as hipóteses do seu teste? Qual o elemento essencial para definir o que será considerado estatisticamente significativo? Foi realizado um teste de normalidade nos dados de idades coletadas e os resultados foram: W = 0.97135 e p-valor = 0.557, à 95% de confiança. O que você pode concluir? A média amostral das idades é 43 anos. Sabe-se que o teste de hipóteses teve p-valor de 0,9841, a nível de significância 95%. Qual a sua conclusão? Referências FREIRE, Sérgio Miranda (2020). Bioestatística Básica. Capítulo 15: Teste de Hipóteses. link Lumen: Concepts in statistics. Hypothesis Testing (4 of 5). link Professor Guru (2017). #01 - O que são Testes de Hipóteses. link "],
["cap9.html", "Capítulo 9 Classificação", " Capítulo 9 Classificação "],
["cap10.html", "Capítulo 10 Regressão", " Capítulo 10 Regressão "],
["references.html", "References", " References "]
]
